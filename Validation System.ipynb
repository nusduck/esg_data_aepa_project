{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一. 验证命名实体识别（NER）模型输出的准确性和可靠性的方法总结\n",
    "\n",
    "1. 交叉验证\n",
    "\n",
    "数据划分: 将数据集划分为训练集、验证集和测试集。确保测试集是未见过的数据，用于评估模型的泛化能力。\n",
    "\n",
    "交叉验证: 使用K折交叉验证，在多个数据子集上训练和评估模型，以确保模型在不同数据上的一致性表现。\n",
    "\n",
    "2. 使用标注数据集\n",
    "\n",
    "人工标注: 创建一个包含手动标注实体的数据集，并将其用作参考。\n",
    "可以使用多名标注者对同一数据进行标注，然后通过一致性检查来确保标注的准确性。\n",
    "\n",
    "评估指标: 使用常见的评估指标来评估模型输出的准确性，如：\n",
    "\n",
    "精确率 (Precision): 正确识别的实体数量 / 被识别的实体总数量\n",
    "\n",
    "召回率 (Recall): 正确识别的实体数量 / 实际实体总数量\n",
    "\n",
    "F1分数: 精确率和召回率的调和平均，F1 = 2 * (精确率 * 召回率) / (精确率 + 召回率)\n",
    "\n",
    "3. 混淆矩阵\n",
    "\n",
    "混淆矩阵: 构建混淆矩阵来可视化模型的预测结果，包括真实标签与预测标签之间的关系。通过混淆矩阵，可以直观地查看哪些实体类型的识别效果较差，并分析具体问题。\n",
    "\n",
    "4. 统计分析\n",
    "\n",
    "错误分析: 统计模型在测试集上识别出的错误，分析常见的错误类型（如假阳性和假阴性），并寻找改进模型的方向。\n",
    "\n",
    "记录模型的预测和真实标签，评估输出的一致性。\n",
    "\n",
    "5. 人工审查\n",
    "\n",
    "人工审查: 随机抽取一定比例的预测结果进行人工审查，检查提取的实体是否符合预期。 通过专家审核来提高模型输出的可信度，尤其是在对某些特定行业的实体提取上。\n",
    "6. 置信度评分\n",
    "\n",
    "置信度机制: 在NER模型中，通常可以为每个实体的预测输出一个置信度评分。根据置信度阈值筛选输出结果，确保只保留高置信度的预测。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. 检查提取的数值是否符合标准："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_extracted_data(extracted_data, standards):\n",
    "    \"\"\"\n",
    "    验证提取的数据是否符合已知标准\n",
    "\n",
    "    Args:\n",
    "        extracted_data (dict): 提取的ESG信息\n",
    "        standards (dict): 已知的标准信息\n",
    "\n",
    "    Returns:\n",
    "        list: 不符合标准的数据项\n",
    "    \"\"\"\n",
    "    violations = []\n",
    "\n",
    "    # 检查碳排放量\n",
    "    if 'carbon_emission' in extracted_data:\n",
    "        emission_value = extracted_data['carbon_emission']\n",
    "        if emission_value < standards['carbon_emission']['min'] or emission_value > standards['carbon_emission']['max']:\n",
    "            violations.append(f\"碳排放量 {emission_value} 不符合标准 ({standards['carbon_emission']['min']} - {standards['carbon_emission']['max']})\")\n",
    "    \n",
    "    return violations\n",
    "\n",
    "# 示例提取数据\n",
    "extracted_data = {\n",
    "    \"carbon_emission\": 1500\n",
    "}\n",
    "\n",
    "# 示例标准\n",
    "standards = {\n",
    "    \"carbon_emission\": {\n",
    "        \"min\": 1000,\n",
    "        \"max\": 2000\n",
    "    }\n",
    "}\n",
    "\n",
    "# 验证提取的数据\n",
    "violations = validate_extracted_data(extracted_data, standards)\n",
    "print(\"验证结果:\", violations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. 置信评分机制\n",
    "目标: 为提取的数据点分配一个置信度评分，以便于判断数据的可靠性。\n",
    "\n",
    "实现步骤：\n",
    "\n",
    "设计评分模型: 可以通过训练模型来预测提取结果的置信度。例如，使用分类模型来评估每个提取数据点的可信度。\n",
    "\n",
    "使用输出概率: 对于NER模型，通常可以直接利用模型输出的概率值作为置信度评分。即对于每个标签，选择最大概率作为置信度。\n",
    "\n",
    "设定阈值: 设定一个置信度阈值，例如70%。只有置信度高于该阈值的数据才被认为是有效的提取结果。\n",
    "\n",
    "动态调整: 随着模型的训练和数据的增加，可以动态调整置信度评分的计算方法和阈值。\n",
    "\n",
    "以下是一个使用NER模型输出概率计算置信度的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_confidence(predictions):\n",
    "    \"\"\"\n",
    "    计算置信度评分\n",
    "\n",
    "    Args:\n",
    "        predictions (list): 模型输出的概率列表\n",
    "\n",
    "    Returns:\n",
    "        float: 置信度评分\n",
    "    \"\"\"\n",
    "    max_prob = np.max(predictions)\n",
    "    return max_prob\n",
    "\n",
    "# 示例NER模型输出的概率\n",
    "predictions = [0.1, 0.3, 0.6]  # 代表标签的概率\n",
    "confidence_score = calculate_confidence(predictions)\n",
    "print(\"置信度评分:\", confidence_score)\n",
    "\n",
    "# 判断是否通过置信度阈值\n",
    "threshold = 0.7\n",
    "if confidence_score > threshold:\n",
    "    print(\"提取结果可信\")\n",
    "else:\n",
    "    print(\"提取结果不可信，需进一步审核\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. 计算NER模型的精确率、召回率和F1分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# 示例真实标签和预测标签\n",
    "true_labels = [\"B-PER\", \"O\", \"B-LOC\", \"O\", \"B-PER\", \"I-PER\"]\n",
    "predicted_labels = [\"B-PER\", \"O\", \"O\", \"B-LOC\", \"B-PER\", \"I-PER\"]\n",
    "\n",
    "# 计算指标\n",
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "print(f\"精确率: {precision:.2f}\")\n",
    "print(f\"召回率: {recall:.2f}\")\n",
    "print(f\"F1分数: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. 交叉验证\n",
    "步骤：\n",
    "\n",
    "准备数据集: 确保数据集包含已标注的文本数据，通常以BIO格式进行标注。\n",
    "\n",
    "划分数据集: 将数据集划分为K个子集，K的值通常为5或10。每次迭代时，选择一个子集作为验证集，其余子集作为训练集。\n",
    "\n",
    "训练和评估模型: 在每次迭代中，使用训练集训练模型，然后在验证集上评估模型性能，记录性能指标（如精确率、召回率和F1分数）。\n",
    "\n",
    "汇总结果: 在所有迭代完成后，计算平均性能指标，以得到模型的整体表现。\n",
    "\n",
    "以下是一个使用Python和scikit-learn实现K折交叉验证的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import BertForTokenClassification, BertTokenizer, Trainer, TrainingArguments\n",
    "\n",
    "# 假设有一个已标注的NER数据集\n",
    "# 示例数据集\n",
    "data = {\n",
    "    'text': [\"Hawking was born in Oxford.\", \"Einstein was born in Ulm.\"],\n",
    "    'bio_labels': [[\"B-PER\", \"O\", \"O\", \"O\", \"B-LOC\", \"O\"], [\"B-PER\", \"O\", \"O\", \"O\", \"B-LOC\", \"O\"]]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 初始化模型和tokenizer\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 计算K折交叉验证\n",
    "k = 2\n",
    "kf = KFold(n_splits=k)\n",
    "\n",
    "# 存储所有折的评估结果\n",
    "all_precision, all_recall, all_f1 = [], [], []\n",
    "\n",
    "for train_index, test_index in kf.split(df):\n",
    "    train_df = df.iloc[train_index]\n",
    "    test_df = df.iloc[test_index]\n",
    "    \n",
    "    # 在训练集上训练模型（需要实现训练过程，略去）\n",
    "    # 这里可以设置训练参数，训练模型\n",
    "    # trainer.train()\n",
    "\n",
    "    # 在测试集上评估模型\n",
    "    # 假设此处预测的 labels 和 true_labels 生成\n",
    "    # 这里进行预测，获取 predicted_labels 和 true_labels\n",
    "    predicted_labels = []  # 通过模型得到的预测标签\n",
    "    true_labels = []      # 测试集的真实标签\n",
    "\n",
    "    # 计算指标\n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "    recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "    all_precision.append(precision)\n",
    "    all_recall.append(recall)\n",
    "    all_f1.append(f1)\n",
    "\n",
    "# 输出平均评估结果\n",
    "print(f\"平均精确率: {np.mean(all_precision):.2f}\")\n",
    "print(f\"平均召回率: {np.mean(all_recall):.2f}\")\n",
    "print(f\"平均F1分数: {np.mean(all_f1):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. 对照ESG标准框架\n",
    "对照已知的ESG框架和标准（如SGX或GRI标准）进行验证。每个提取的实体（如某公司的温室气体排放数据）需要与标准中的相关类别进行匹配，确保其符合标准定义。\n",
    "\n",
    "使用正则表达式或已标注的术语库比对提取信息和标准指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取SGX标准框架\n",
    "esg_standards <- read.csv('sgx_esg_standards.csv')\n",
    "\n",
    "# 对照提取数据的类别\n",
    "validate_esg <- function(extracted_data, esg_standards) {\n",
    "  matches <- list()\n",
    "  for (data_point in extracted_data) {\n",
    "    if (data_point$category %in% esg_standards$category) {\n",
    "      matches <- append(matches, data_point)\n",
    "    }\n",
    "  }\n",
    "  return(matches)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. 信心评分机制：\n",
    "每次从报告中提取的信息都赋予一个“信心评分”，表示该信息的可靠性。评分可以基于提取模型的置信度、数据匹配的频率、以及与标准的符合程度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成信心评分\n",
    "generate_confidence_score <- function(data_point, model_confidence, match_with_standard) {\n",
    "  if (match_with_standard) {\n",
    "    score <- model_confidence * 1.2  # 匹配标准则增加20%的信心\n",
    "  } else {\n",
    "    score <- model_confidence\n",
    "  }\n",
    "  return(score)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. 人机交互"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(shiny)\n",
    "\n",
    "# 创建一个简单的审阅界面\n",
    "ui <- fluidPage(\n",
    "  titlePanel(\"ESG Data Review\"),\n",
    "  tableOutput(\"esg_table\"),\n",
    "  actionButton(\"approve\", \"Approve\"),\n",
    "  actionButton(\"reject\", \"Reject\")\n",
    ")\n",
    "\n",
    "server <- function(input, output) {\n",
    "  # 显示提取的数据\n",
    "  output$esg_table <- renderTable({\n",
    "    extracted_data\n",
    "  })\n",
    "\n",
    "  observeEvent(input$approve, {\n",
    "    # 记录审核通过的结果\n",
    "    approved_data <- append(approved_data, extracted_data)\n",
    "  })\n",
    "\n",
    "  observeEvent(input$reject, {\n",
    "    # 记录审核不通过的结果\n",
    "    rejected_data <- append(rejected_data, extracted_data)\n",
    "  })\n",
    "}\n",
    "\n",
    "shinyApp(ui = ui, server = server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. 适应不断变化的ESG标准与公司报告风格--迁移学习\n",
    "使用预训练的语言模型（如BERT、GPT）进行迁移学习，适应新行业或新的ESG框架。可以基于新数据进行微调模型。\n",
    "\n",
    "持续学习系统：\n",
    "实现一个持续学习的管道，每当有新数据输入，模型会自动更新和优化。\n",
    "设计自动反馈机制，从人类审核中提取反馈，进一步优化模型性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForTokenClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset\n",
    "import torch\n",
    "\n",
    "# 加载预训练的BERT模型和分词器\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=NUM_LABELS)\n",
    "\n",
    "# 准备新的训练数据（假设已经有一个新的数据集）\n",
    "new_texts = [...]  # 新的ESG文本\n",
    "new_labels = [...]  # 适当的标签\n",
    "\n",
    "# 创建数据集\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = tokenizer(text, truncation=True, padding='max_length', return_tensors='pt')\n",
    "        encoding['labels'] = torch.tensor(label)\n",
    "        return {key: val.squeeze() for key, val in encoding.items()}\n",
    "\n",
    "new_dataset = CustomDataset(new_texts, new_labels)\n",
    "\n",
    "# 设置训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    ")\n",
    "\n",
    "# 使用Trainer进行训练\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=new_dataset,\n",
    ")\n",
    "\n",
    "# 开始微调\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、示例文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例文本\n",
    "esg_report_text = \"\"\"\n",
    "In 2023, our company achieved significant milestones in sustainability. We reduced our greenhouse gas emissions by 25% compared to the previous year. Additionally, 50% of our energy consumption now comes from renewable sources, demonstrating our commitment to clean energy. In terms of water usage, we managed to decrease water consumption by 10% in our operations.\n",
    "\"\"\"\n",
    "\n",
    "# 模拟的ESG提取信息\n",
    "extracted_data = [\n",
    "    {\"category\": \"GHG Emissions\", \"value\": \"25% reduction\", \"unit\": \"%\"},\n",
    "    {\"category\": \"Renewable Energy\", \"value\": \"50% consumption\", \"unit\": \"%\"},\n",
    "    {\"category\": \"Water Consumption\", \"value\": \"10% reduction\", \"unit\": \"%\"}\n",
    "]\n",
    "\n",
    "\n",
    "# 定义验证标准 (GRI framework or any other standards)\n",
    "esg_standards = {\n",
    "    \"GHG Emissions\": \"Reduction of greenhouse gas emissions\",\n",
    "    \"Renewable Energy\": \"Increase in renewable energy usage\",\n",
    "    \"Water Consumption\": \"Reduction in water consumption\"\n",
    "}\n",
    "\n",
    "# 计算置信度\n",
    "def validate_extracted_data(extracted_data, esg_standards):\n",
    "    validated_results = []\n",
    "    for data in extracted_data:\n",
    "        category = data[\"category\"]\n",
    "        value = data[\"value\"]\n",
    "        \n",
    "        # 初始置信度设为1.0\n",
    "        confidence_score = 1.0\n",
    "        \n",
    "        # 如果该类别在标准中有定义，增加置信度\n",
    "        if category in esg_standards:\n",
    "            confidence_score += 0.2  # 符合标准，增加置信度\n",
    "        \n",
    "        validated_results.append({\n",
    "            \"category\": category,\n",
    "            \"value\": value,\n",
    "            \"standard\": esg_standards.get(category, \"No standard found\"),\n",
    "            \"confidence\": confidence_score\n",
    "        })\n",
    "    \n",
    "    return validated_results\n",
    "\n",
    "# 调用验证函数\n",
    "validated_data = validate_extracted_data(extracted_data, esg_standards)\n",
    "\n",
    "# 显示验证结果\n",
    "for item in validated_data:\n",
    "    print(f\"Category: {item['category']}, Value: {item['value']}, Standard: {item['standard']}, Confidence: {item['confidence']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_report_text = \"\"\"\n",
    "In 2023, our company reduced carbon emissions by 20%, increased renewable energy usage to 60%, and improved waste recycling efficiency by 15%.\n",
    "\"\"\"\n",
    "# 模拟模型提取的 ESG 信息\n",
    "extracted_data = [\n",
    "    {\"category\": \"Carbon Emissions\", \"value\": \"20% reduction\", \"confidence\": 0.9},\n",
    "    {\"category\": \"Renewable Energy\", \"value\": \"60% increase\", \"confidence\": 0.85},\n",
    "    {\"category\": \"Waste Recycling\", \"value\": \"15% efficiency\", \"confidence\": 0.8}\n",
    "]\n",
    "\n",
    "# 模拟专家提供的反馈\n",
    "def human_in_the_loop_feedback(extracted_data):\n",
    "    print(\"Initial Model Output:\")\n",
    "    for data in extracted_data:\n",
    "        print(f\"Category: {data['category']}, Value: {data['value']}, Confidence: {data['confidence']}\")\n",
    "    \n",
    "    # 模拟专家的修改\n",
    "    print(\"\\nExpert Feedback:\")\n",
    "    feedback_data = [\n",
    "        {\"category\": \"Carbon Emissions\", \"value\": \"25% reduction\", \"confidence\": 0.95},\n",
    "        {\"category\": \"Renewable Energy\", \"value\": \"65% increase\", \"confidence\": 0.90},\n",
    "        {\"category\": \"Waste Recycling\", \"value\": \"20% efficiency\", \"confidence\": 0.85}\n",
    "    ]\n",
    "    \n",
    "    # 返回修正后的数据\n",
    "    return feedback_data\n",
    "\n",
    "# 专家反馈并更新模型结果\n",
    "updated_data = human_in_the_loop_feedback(extracted_data)\n",
    "\n",
    "# 输出修正后的数据\n",
    "print(\"\\nUpdated Model Output after Expert Feedback:\")\n",
    "for data in updated_data:\n",
    "    print(f\"Category: {data['category']}, Value: {data['value']}, Confidence: {data['confidence']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT-序列分类\n",
    "esg_report_text = \"\"\"\n",
    "Our company aims to achieve carbon neutrality by 2030, and in 2023, we successfully increased our renewable energy usage to 75%.\n",
    "\"\"\"\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "import torch\n",
    "\n",
    "# 加载预训练的 BERT 模型和分词器\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)  # 3类ESG类别\n",
    "\n",
    "# 模拟 ESG 报告的分类任务\n",
    "esg_reports = [\n",
    "    \"Our company aims to reduce carbon emissions by 25% by 2025.\",\n",
    "    \"In 2023, we increased renewable energy usage to 75%.\",\n",
    "    \"Water usage was reduced by 10%.\"\n",
    "]\n",
    "\n",
    "# Tokenize 输入文本\n",
    "inputs = tokenizer(esg_reports, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# 模拟分类标签 (0: Carbon Emissions, 1: Renewable Energy, 2: Water Usage)\n",
    "labels = torch.tensor([0, 1, 2])\n",
    "\n",
    "# 定义优化器\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# 微调模型（1个 epoch）\n",
    "model.train()\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# 模拟新的 ESG 报告来测试微调后的模型\n",
    "new_report = \"The company aims to achieve carbon neutrality by 2030.\"\n",
    "inputs = tokenizer(new_report, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(**inputs).logits\n",
    "    predicted_class = torch.argmax(predictions, dim=1).item()\n",
    "\n",
    "# 输出预测的类别\n",
    "categories = [\"Carbon Emissions\", \"Renewable Energy\", \"Water Usage\"]\n",
    "print(f\"Predicted Category: {categories[predicted_class]}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
