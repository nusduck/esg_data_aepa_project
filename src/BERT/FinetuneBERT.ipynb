{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizerFast, BertForTokenClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定包含JSON文件的文件夹路径\n",
    "folder_path = '../data/esg_label_result'\n",
    "\n",
    "# 使用glob获取文件夹中所有的JSON文件\n",
    "json_files = glob.glob(os.path.join(folder_path, \"*.json\"))\n",
    "\n",
    "all_data = []\n",
    "\n",
    "# 逐个读取每个JSON文件\n",
    "for file in json_files:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        all_data.extend(data)  # 将所有JSON文件的数据合并到一个列表中\n",
    "\n",
    "# # 打印合并后的数据\n",
    "# print(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取JSON文件 \n",
    "# with open('../data/esg_label_result/AF Global Limited_report_filtered.json', 'r') as f:\n",
    "#     data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [item for item in all_data if \"error\" not in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict ={\n",
    "        \"B-ENV_GHG_AET\": 0,\n",
    "        \"I-ENV_GHG_AET\": 0,\n",
    "        \"B-ENV_GHG_AE1\": 0,\n",
    "        \"I-ENV_GHG_AE1\": 0,\n",
    "        \"B-ENV_GHG_AE2\": 0,\n",
    "        \"I-ENV_GHG_AE2\": 0,\n",
    "        \"B-ENV_GHG_AE3\": 0,\n",
    "        \"I-ENV_GHG_AE3\": 0,\n",
    "        \"B-ENV_GHG_EIT\": 0,\n",
    "        \"I-ENV_GHG_EIT\": 0,\n",
    "        \"B-ENV_GHG_EI1\": 0,\n",
    "        \"I-ENV_GHG_EI1\": 0,\n",
    "        \"B-ENV_GHG_EI2\": 0,\n",
    "        \"I-ENV_GHG_EI2\": 0,\n",
    "        \"B-ENV_GHG_EI3\": 0,\n",
    "        \"I-ENV_GHG_EI3\": 0,\n",
    "        \"B-ENV_ENC_TEC\": 0,\n",
    "        \"I-ENV_ENC_TEC\": 0,\n",
    "        \"B-ENV_ENC_ECI\": 0,\n",
    "        \"I-ENV_ENC_ECI\": 0,\n",
    "        \"B-ENV_WAC_TWC\": 0,\n",
    "        \"I-ENV_WAC_TWC\": 0,\n",
    "        \"B-ENV_WAC_WCI\": 0,\n",
    "        \"I-ENV_WAC_WCI\": 0,\n",
    "        \"B-ENV_WAG_TWG\": 0,\n",
    "        \"I-ENV_WAG_TWG\": 0,\n",
    "        \"B-SOC_GED_CEG_M\": 0,\n",
    "        \"I-SOC_GED_CEG_M\": 0,\n",
    "        \"B-SOC_GED_CEG_F\": 0,\n",
    "        \"I-SOC_GED_CEG_F\": 0,\n",
    "        \"B-SOC_GED_NHG_M\": 0,\n",
    "        \"I-SOC_GED_NHG_M\": 0,\n",
    "        \"B-SOC_GED_NHG_F\": 0,\n",
    "        \"I-SOC_GED_NHG_F\": 0,\n",
    "        \"B-SOC_GED_ETG_M\": 0,\n",
    "        \"I-SOC_GED_ETG_M\": 0,\n",
    "        \"B-SOC_GED_ETG_F\": 0,\n",
    "        \"I-SOC_GED_ETG_F\": 0,\n",
    "        \"B-SOC_AGD_CEA_U30\": 0,\n",
    "        \"I-SOC_AGD_CEA_U30\": 0,\n",
    "        \"B-SOC_AGD_CEA_B35\": 0,\n",
    "        \"I-SOC_AGD_CEA_B35\": 0,\n",
    "        \"B-SOC_AGD_CEA_A50\": 0,\n",
    "        \"I-SOC_AGD_CEA_A50\": 0,\n",
    "        \"B-SOC_AGD_NHI_U30\": 0,\n",
    "        \"I-SOC_AGD_NHI_U30\": 0,\n",
    "        \"B-SOC_AGD_NHI_B35\": 0,\n",
    "        \"I-SOC_AGD_NHI_B35\": 0,\n",
    "        \"B-SOC_AGD_NHI_A50\": 0,\n",
    "        \"I-SOC_AGD_NHI_A50\": 0,\n",
    "        \"B-SOC_AGD_TOR_U30\": 0,\n",
    "        \"I-SOC_AGD_TOR_U30\": 0,\n",
    "        \"B-SOC_AGD_TOR_B35\": 0,\n",
    "        \"I-SOC_AGD_TOR_B35\": 0,\n",
    "        \"B-SOC_AGD_TOR_A50\": 0,\n",
    "        \"I-SOC_AGD_TOR_A50\": 0,\n",
    "        \"B-SOC_DEV_ATH_M\": 0,\n",
    "        \"I-SOC_DEV_ATH_M\": 0,\n",
    "        \"B-SOC_DEV_ATH_F\": 0,\n",
    "        \"I-SOC_DEV_ATH_F\": 0,\n",
    "        \"B-SOC_OHS_FAT\": 0,\n",
    "        \"I-SOC_OHS_FAT\": 0,\n",
    "        \"B-SOC_OHS_HCI\": 0,\n",
    "        \"I-SOC_OHS_HCI\": 0,\n",
    "        \"B-SOC_OHS_REC\": 0,\n",
    "        \"I-SOC_OHS_REC\": 0,\n",
    "        \"B-SOC_OHS_RWI\": 0,\n",
    "        \"I-SOC_OHS_RWI\": 0,\n",
    "        \"B-GOV_BOC_BIN\": 0,\n",
    "        \"I-GOV_BOC_BIN\": 0,\n",
    "        \"B-GOV_BOC_WOB\": 0,\n",
    "        \"I-GOV_BOC_WOB\": 0,\n",
    "        \"B-GOV_MAD_WMT\": 0,\n",
    "        \"I-GOV_MAD_WMT\": 0,\n",
    "        \"B-GOV_ETB_ACD\": 0,\n",
    "        \"I-GOV_ETB_ACD\": 0,\n",
    "        \"B-GOV_ETB_ACT_N\": 0,\n",
    "        \"I-GOV_ETB_ACT_N\": 0,\n",
    "        \"B-GOV_ETB_ACT_P\": 0,\n",
    "        \"I-GOV_ETB_ACT_P\": 0,\n",
    "        \"B-GOV_CER_LRC\": 0,\n",
    "        \"I-GOV_CER_LRC\": 0,\n",
    "        \"B-GOV_ALF_AFD\": 0,\n",
    "        \"I-GOV_ALF_AFD\": 0,\n",
    "        \"B-GOV_ASS_ASR\": 0,\n",
    "        \"I-GOV_ASS_ASR\": 0,\n",
    "        \"B-VALUE\": 0,\n",
    "        \"I-VALUE\": 0,\n",
    "        \"B-UNIT\": 0,\n",
    "        \"I-UNIT\": 0,\n",
    "        \"O\": 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取BIO标注数据\n",
    "texts = []\n",
    "labels = []\n",
    "err = []\n",
    "\n",
    "for entry in data:\n",
    "    text = entry['text']\n",
    "    entity_labels = [\"O\"] * len(text)  # 初始化为'O'\n",
    "\n",
    "    for entity in entry['entity']:\n",
    "        start, end, label = entity['start'], entity['end'], entity['labels'][0]\n",
    "        if label not in label_dict:\n",
    "            continue\n",
    "        # 检查字典情况\n",
    "        # if end > len(entity_labels):\n",
    "        #     err.append(data.index(entry))\n",
    "        #     continue\n",
    "        for i in range(start, end):\n",
    "            entity_labels[i] = label\n",
    "\n",
    "    texts.append(list(text))\n",
    "    labels.append(entity_labels)\n",
    "\n",
    "# 将数据转换为 DataFrame 格式\n",
    "df = pd.DataFrame({\"tokens\": texts, \"ner_tags\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "无实体句子数量: 936\n",
      "实体句子数量: 5153\n",
      "合并后的数据集样本数: 6089\n"
     ]
    }
   ],
   "source": [
    "# 非实体句删除\n",
    "\n",
    "no_entity_data = df[df['ner_tags'].apply(lambda x: all(label == \"O\" for label in x))]\n",
    "entity_data = df[~df['ner_tags'].apply(lambda x: all(label == \"O\" for label in x))]\n",
    "\n",
    "# 保留 15% 的无实体句子\n",
    "no_entity_sample = no_entity_data.sample(frac=0.15, random_state=42)\n",
    "\n",
    "# 合并数据\n",
    "balanced_df = pd.concat([entity_data, no_entity_sample])\n",
    "\n",
    "# 打乱数据集顺序\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 检查新的数据分布\n",
    "print(\"无实体句子数量:\", len(no_entity_sample))\n",
    "print(\"实体句子数量:\", len(entity_data))\n",
    "print(\"合并后的数据集样本数:\", len(balanced_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义需要合并的标签字典，将稀有标签映射到新的标签名\n",
    "merge_dict = {\n",
    "    \"B-SOC_AGD_TOR_U30\": \"B-SOC_AGD_TOR\",\n",
    "    \"I-SOC_AGD_TOR_U30\": \"I-SOC_AGD_TOR\",\n",
    "    \"B-SOC_AGD_TOR_B35\": \"B-SOC_AGD_TOR\",\n",
    "    \"I-SOC_AGD_TOR_B35\": \"I-SOC_AGD_TOR\",\n",
    "    \"B-SOC_AGD_TOR_A50\": \"B-SOC_AGD_TOR\",\n",
    "    \"I-SOC_AGD_TOR_A50\": \"I-SOC_AGD_TOR\",\n",
    "    \n",
    "    'B-SOC_AGD_NHI_B35': 'B-SOC_AGD_NHI',\n",
    "    'B-SOC_AGD_NHI_A50': 'B-SOC_AGD_NHI',\n",
    "    'B-SOC_AGD_NHI_U30': 'B-SOC_AGD_NHI',\n",
    "    'I-SOC_AGD_NHI_U30': 'I-SOC_AGD_NHI',\n",
    "    'I-SOC_AGD_NHI_B35': 'I-SOC_AGD_NHI',\n",
    "    'I-SOC_AGD_NHI_A50': 'I-SOC_AGD_NHI',\n",
    "    \n",
    "    'B-ENV_GHG_EI1' : 'B-ENV_GHG_EI',\n",
    "    'I-ENV_GHG_EI1' : 'I-ENV_GHG_EI',\n",
    "    'B-ENV_GHG_EI2' : 'B-ENV_GHG_EI',\n",
    "    'I-ENV_GHG_EI2' : 'I-ENV_GHG_EI',\n",
    "    'B-ENV_GHG_EI3' : 'B-ENV_GHG_EI',\n",
    "    'I-ENV_GHG_EI3' : 'I-ENV_GHG_EI',\n",
    "    \n",
    "    'B-SOC_AGD_CEA_U30' : 'B-SOC_AGD_CEA',\n",
    "    'I-SOC_AGD_CEA_U30' : 'I-SOC_AGD_CEA',\n",
    "    'B-SOC_AGD_CEA_B35' : 'B-SOC_AGD_CEA',\n",
    "    'I-SOC_AGD_CEA_B35' : 'I-SOC_AGD_CEA',\n",
    "    'B-SOC_AGD_CEA_A50' : 'B-SOC_AGD_CEA',\n",
    "    'I-SOC_AGD_CEA_A50' : 'I-SOC_AGD_CEA',\n",
    "    \n",
    "    'B-SOC_GED_ETG_F' : 'B-SOC_GED_ETG',\n",
    "    'I-SOC_GED_ETG_F' : 'I-SOC_GED_ETG',\n",
    "    'B-SOC_GED_ETG_M' : 'B-SOC_GED_ETG',\n",
    "    'I-SOC_GED_ETG_M' : 'I-SOC_GED_ETG',\n",
    "    'B-SOC_GED_NHG_M' : 'B-SOC_GED_NHG',\n",
    "    'I-SOC_GED_NHG_M' : 'I-SOC_GED_NHG',\n",
    "    'B-SOC_GED_NHG_F' : 'B-SOC_GED_NHG',\n",
    "    'I-SOC_GED_NHG_F' : 'I-SOC_GED_NHG'\n",
    "    \n",
    "    # 添加更多需要合并的标签映射\n",
    "}\n",
    "\n",
    "# 定义一个函数，用于将标签序列中的稀有标签合并\n",
    "def merge_labels(label_sequence, merge_dict):\n",
    "    return [merge_dict.get(label, label) for label in label_sequence]\n",
    "\n",
    "# 应用标签合并函数到 DataFrame 的 'labels' 列\n",
    "balanced_df['ner_tags'] = balanced_df['ner_tags'].apply(lambda x: merge_labels(x, merge_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后的标签分布:\n",
      "O                  1153555\n",
      "I-GOV_ALF_AFD        29144\n",
      "B-GOV_ALF_AFD        26855\n",
      "B-VALUE              15533\n",
      "B-GOV_ETB_ACD        10952\n",
      "I-GOV_ETB_ACD         8668\n",
      "B-GOV_BOC_BIN         8135\n",
      "I-GOV_BOC_BIN         8107\n",
      "I-SOC_DEV_ATH_M       6157\n",
      "B-UNIT                5897\n",
      "B-ENV_ENC_TEC         5709\n",
      "B-ENV_GHG_AET         5702\n",
      "B-SOC_DEV_ATH_M       5700\n",
      "I-SOC_OHS_RWI         5246\n",
      "B-SOC_OHS_RWI         5096\n",
      "I-ENV_ENC_TEC         4947\n",
      "I-ENV_GHG_AET         4775\n",
      "I-UNIT                4584\n",
      "I-ENV_WAG_TWG         3689\n",
      "B-SOC_GED_CEG_F       3288\n",
      "B-ENV_WAG_TWG         3052\n",
      "I-GOV_CER_LRC         2911\n",
      "I-SOC_GED_CEG_F       2553\n",
      "I-VALUE               2248\n",
      "B-GOV_CER_LRC         2176\n",
      "I-ENV_WAC_TWC         1971\n",
      "B-ENV_WAC_TWC         1678\n",
      "I-GOV_ASS_ASR         1416\n",
      "B-GOV_ASS_ASR         1349\n",
      "I-ENV_ENC_ECI         1317\n",
      "B-ENV_ENC_ECI         1258\n",
      "I-ENV_GHG_EIT         1161\n",
      "I-ENV_GHG_AE3         1158\n",
      "B-SOC_OHS_REC         1127\n",
      "I-SOC_OHS_REC         1119\n",
      "I-ENV_GHG_AE2         1108\n",
      "I-ENV_GHG_AE1         1080\n",
      "B-ENV_GHG_AE1          996\n",
      "B-GOV_ETB_ACT_N        925\n",
      "I-GOV_ETB_ACT_N        851\n",
      "I-SOC_GED_CEG_M        849\n",
      "B-ENV_GHG_EIT          814\n",
      "B-SOC_GED_CEG_M        762\n",
      "I-GOV_MAD_WMT          730\n",
      "B-GOV_MAD_WMT          686\n",
      "B-ENV_GHG_AE3          658\n",
      "I-GOV_ETB_ACT_P        647\n",
      "B-ENV_GHG_AE2          629\n",
      "B-SOC_DEV_ATH_F        546\n",
      "I-ENV_WAC_WCI          543\n",
      "B-GOV_ETB_ACT_P        526\n",
      "I-SOC_DEV_ATH_F        495\n",
      "B-SOC_OHS_HCI          400\n",
      "B-SOC_AGD_CEA          349\n",
      "B-SOC_OHS_FAT          340\n",
      "B-ENV_WAC_WCI          306\n",
      "I-SOC_AGD_CEA          304\n",
      "I-ENV_GHG_EI           301\n",
      "B-SOC_GED_NHG          293\n",
      "I-SOC_OHS_HCI          259\n",
      "I-SOC_GED_NHG          249\n",
      "I-SOC_OHS_FAT          231\n",
      "B-ENV_GHG_EI           220\n",
      "B-SOC_GED_ETG          181\n",
      "I-GOV_BOC_WOB          128\n",
      "B-GOV_BOC_WOB           99\n",
      "I-SOC_GED_ETG           95\n",
      "B-SOC_AGD_NHI           45\n",
      "I-SOC_AGD_NHI           35\n",
      "B-SOC_AGD_TOR           23\n",
      "I-SOC_AGD_TOR           16\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 设置 pandas 的显示选项，防止省略\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# 检查标签合并后的分布\n",
    "all_labels_flat = [item for sublist in balanced_df['ner_tags'] for item in sublist]\n",
    "label_counts_after_merge = pd.Series(all_labels_flat).value_counts()\n",
    "\n",
    "print(\"合并后的标签分布:\")\n",
    "print(label_counts_after_merge)\n",
    "\n",
    "# 恢复默认设置（可选）\n",
    "pd.reset_option('display.max_rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 查找标签所在句子\n",
    "# # 目标标签\n",
    "# target_label = \"B-SOC_AGD_TOR\"\n",
    "\n",
    "# # 筛选出包含目标标签的句子\n",
    "# sentences_with_label = balanced_df_resampled[balanced_df_resampled['ner_tags'].apply(lambda x: target_label in x)]\n",
    "\n",
    "# # 查看筛选结果\n",
    "# print(\"包含标签\", target_label, \"的句子数量:\", len(sentences_with_label))\n",
    "# print(sentences_with_label[['tokens', 'ner_tags']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# # 假设 labels 列表中存储了每个文本的标签序列\n",
    "# # 将所有标签展开为一个列表，并使用 Counter 统计每种标签的数量\n",
    "# all_labels = [label for sequence in labels for label in sequence]\n",
    "# label_counts = Counter(all_labels)\n",
    "\n",
    "# # 打印每种实体的数量\n",
    "# for label, count in label_counts.items():\n",
    "#     print(f\"实体标签 '{label}' 的数量为: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过采样后的数据集大小: 7089\n"
     ]
    }
   ],
   "source": [
    "# 定义低频标签的阈值\n",
    "low_count_threshold = 500\n",
    "\n",
    "# 获取所有标签的数量分布\n",
    "all_labels_flat = [item for sublist in balanced_df['ner_tags'] for item in sublist]\n",
    "label_counts = pd.Series(all_labels_flat).value_counts()  # 假设这是一个标签-数量的字典或 Series\n",
    "\n",
    "# 找出所有低频标签\n",
    "low_frequency_labels = [label for label, count in label_counts.items() if count < low_count_threshold]\n",
    "\n",
    "# 初始化一个新的 DataFrame 来存储过采样的句子\n",
    "balanced_df_resampled = balanced_df.copy()\n",
    "\n",
    "# 遍历每一个低频标签，筛选并过采样包含该标签的句子\n",
    "for label in low_frequency_labels:\n",
    "    # 筛选出包含当前标签的句子\n",
    "    sentences_with_label = balanced_df[balanced_df['ner_tags'].apply(lambda x: label in x)]\n",
    "    \n",
    "    # 确认是否需要过采样\n",
    "    if len(sentences_with_label) < low_count_threshold:\n",
    "        # 过采样该标签的句子\n",
    "        sentences_with_label_upsampled = resample(sentences_with_label, \n",
    "                                                  replace=True, \n",
    "                                                  n_samples=50, \n",
    "                                                  random_state=42)\n",
    "        \n",
    "        # 将过采样后的数据合并到主数据集中\n",
    "        balanced_df_resampled = pd.concat([balanced_df_resampled, sentences_with_label_upsampled])\n",
    "\n",
    "# 打乱数据集\n",
    "balanced_df_resampled = balanced_df_resampled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# 查看结果\n",
    "print(\"过采样后的数据集大小:\", len(balanced_df_resampled))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后的标签分布:\n",
      "O                  1446378\n",
      "I-GOV_ALF_AFD        36557\n",
      "B-GOV_ALF_AFD        30632\n",
      "B-VALUE              27667\n",
      "B-GOV_ETB_ACD        11621\n",
      "I-UNIT               10829\n",
      "B-UNIT               10115\n",
      "I-GOV_ETB_ACD         9650\n",
      "B-GOV_BOC_BIN         8799\n",
      "I-GOV_BOC_BIN         8334\n",
      "I-SOC_DEV_ATH_M       6850\n",
      "I-ENV_WAG_TWG         6585\n",
      "I-SOC_OHS_RWI         6541\n",
      "B-SOC_DEV_ATH_M       6247\n",
      "B-ENV_ENC_TEC         6170\n",
      "B-SOC_OHS_RWI         6102\n",
      "B-ENV_GHG_AET         5880\n",
      "I-ENV_ENC_TEC         5716\n",
      "I-ENV_GHG_AET         4976\n",
      "B-SOC_GED_CEG_F       4473\n",
      "B-ENV_WAG_TWG         4225\n",
      "I-SOC_GED_CEG_F       3424\n",
      "B-SOC_DEV_ATH_F       3308\n",
      "B-SOC_GED_ETG         3162\n",
      "I-SOC_GED_ETG         3099\n",
      "I-GOV_CER_LRC         2991\n",
      "I-SOC_DEV_ATH_F       2710\n",
      "I-ENV_WAC_TWC         2705\n",
      "B-SOC_OHS_REC         2601\n",
      "B-SOC_GED_NHG         2590\n",
      "I-SOC_OHS_REC         2585\n",
      "B-SOC_OHS_HCI         2563\n",
      "I-VALUE               2505\n",
      "B-SOC_OHS_FAT         2495\n",
      "I-SOC_GED_NHG         2258\n",
      "B-GOV_CER_LRC         2255\n",
      "I-ENV_GHG_EIT         2182\n",
      "I-ENV_GHG_EI          2181\n",
      "I-ENV_ENC_ECI         2136\n",
      "B-ENV_WAC_TWC         2099\n",
      "I-SOC_OHS_FAT         1908\n",
      "I-ENV_WAC_WCI         1905\n",
      "I-SOC_OHS_HCI         1827\n",
      "B-ENV_GHG_EI          1746\n",
      "I-ENV_GHG_AE2         1714\n",
      "B-ENV_ENC_ECI         1560\n",
      "B-ENV_GHG_EIT         1475\n",
      "I-ENV_GHG_AE1         1474\n",
      "I-SOC_AGD_CEA         1444\n",
      "B-SOC_AGD_CEA         1438\n",
      "B-SOC_AGD_TOR         1436\n",
      "I-GOV_ASS_ASR         1416\n",
      "B-GOV_ASS_ASR         1349\n",
      "B-ENV_GHG_AE1         1320\n",
      "B-SOC_AGD_NHI         1290\n",
      "B-SOC_GED_CEG_M       1264\n",
      "I-SOC_GED_CEG_M       1250\n",
      "I-ENV_GHG_AE3         1216\n",
      "I-GOV_BOC_WOB         1207\n",
      "I-SOC_AGD_NHI         1181\n",
      "I-SOC_AGD_TOR         1168\n",
      "B-ENV_WAC_WCI         1096\n",
      "B-GOV_ETB_ACT_N        975\n",
      "I-GOV_ETB_ACT_N        851\n",
      "B-ENV_GHG_AE2          837\n",
      "I-GOV_MAD_WMT          754\n",
      "B-GOV_BOC_WOB          722\n",
      "B-GOV_MAD_WMT          721\n",
      "B-ENV_GHG_AE3          700\n",
      "I-GOV_ETB_ACT_P        647\n",
      "B-GOV_ETB_ACT_P        526\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 设置 pandas 的显示选项，防止省略\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# 检查标签合并后的分布\n",
    "all_labels_flat = [item for sublist in balanced_df_resampled['ner_tags'] for item in sublist]\n",
    "label_counts_after_merge = pd.Series(all_labels_flat).value_counts()\n",
    "\n",
    "print(\"合并后的标签分布:\")\n",
    "print(label_counts_after_merge)\n",
    "\n",
    "# 恢复默认设置（可选）\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据转换为 Hugging Face 的 Dataset 格式\n",
    "dataset = Dataset.from_pandas(balanced_df_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有独特标签: ['B-ENV_ENC_ECI', 'B-ENV_ENC_TEC', 'B-ENV_GHG_AE1', 'B-ENV_GHG_AE2', 'B-ENV_GHG_AE3', 'B-ENV_GHG_AET', 'B-ENV_GHG_EI', 'B-ENV_GHG_EIT', 'B-ENV_WAC_TWC', 'B-ENV_WAC_WCI', 'B-ENV_WAG_TWG', 'B-GOV_ALF_AFD', 'B-GOV_ASS_ASR', 'B-GOV_BOC_BIN', 'B-GOV_BOC_WOB', 'B-GOV_CER_LRC', 'B-GOV_ETB_ACD', 'B-GOV_ETB_ACT_N', 'B-GOV_ETB_ACT_P', 'B-GOV_MAD_WMT', 'B-SOC_AGD_CEA', 'B-SOC_AGD_NHI', 'B-SOC_AGD_TOR', 'B-SOC_DEV_ATH_F', 'B-SOC_DEV_ATH_M', 'B-SOC_GED_CEG_F', 'B-SOC_GED_CEG_M', 'B-SOC_GED_ETG', 'B-SOC_GED_NHG', 'B-SOC_OHS_FAT', 'B-SOC_OHS_HCI', 'B-SOC_OHS_REC', 'B-SOC_OHS_RWI', 'B-UNIT', 'B-VALUE', 'I-ENV_ENC_ECI', 'I-ENV_ENC_TEC', 'I-ENV_GHG_AE1', 'I-ENV_GHG_AE2', 'I-ENV_GHG_AE3', 'I-ENV_GHG_AET', 'I-ENV_GHG_EI', 'I-ENV_GHG_EIT', 'I-ENV_WAC_TWC', 'I-ENV_WAC_WCI', 'I-ENV_WAG_TWG', 'I-GOV_ALF_AFD', 'I-GOV_ASS_ASR', 'I-GOV_BOC_BIN', 'I-GOV_BOC_WOB', 'I-GOV_CER_LRC', 'I-GOV_ETB_ACD', 'I-GOV_ETB_ACT_N', 'I-GOV_ETB_ACT_P', 'I-GOV_MAD_WMT', 'I-SOC_AGD_CEA', 'I-SOC_AGD_NHI', 'I-SOC_AGD_TOR', 'I-SOC_DEV_ATH_F', 'I-SOC_DEV_ATH_M', 'I-SOC_GED_CEG_F', 'I-SOC_GED_CEG_M', 'I-SOC_GED_ETG', 'I-SOC_GED_NHG', 'I-SOC_OHS_FAT', 'I-SOC_OHS_HCI', 'I-SOC_OHS_REC', 'I-SOC_OHS_RWI', 'I-UNIT', 'I-VALUE', 'O']\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "# 使用集合存储所有独特标签，避免重复\n",
    "unique_labels = set(label_counts_after_merge.index)\n",
    "\n",
    "# 将集合转换为列表并排序\n",
    "unique_labels = sorted(list(unique_labels))\n",
    "\n",
    "# 查看所有标签\n",
    "print(\"所有独特标签:\", unique_labels)\n",
    "print(len(unique_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split['train']\n",
    "eval_dataset = train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\esg\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"nbroad/ESG-BERT\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], \n",
    "        truncation=True, \n",
    "        is_split_into_words=True, \n",
    "        padding=True\n",
    "    )\n",
    "    labels = []\n",
    "\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)  # 忽略位置\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label2id[label[word_idx]])  # 将标签转换为整数 ID\n",
    "            else:\n",
    "                # 对于当前词的子词部分，通常不需要计算损失，除非你想保持每个子词的相同标签\n",
    "                label_ids.append(label2id[label[word_idx]] if label[word_idx].startswith(\"I-\") else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define compute_metrics function for evaluation\n",
    "def compute_metrics(pred):\n",
    "    # Extract predictions and labels\n",
    "    predictions, labels = pred\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    \n",
    "    # Remove ignored index (special tokens)\n",
    "    true_labels = [[label for label, pred in zip(label_row, pred_row) if label != -100] \n",
    "                   for label_row, pred_row in zip(labels, predictions)]\n",
    "    true_predictions = [[pred for label, pred in zip(label_row, pred_row) if label != -100]\n",
    "                        for label_row, pred_row in zip(labels, predictions)]\n",
    "    \n",
    "    # Flatten lists\n",
    "    true_labels = [item for sublist in true_labels for item in sublist]\n",
    "    true_predictions = [item for sublist in true_predictions for item in sublist]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, true_predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, true_predictions, average='weighted')\n",
    "    \n",
    "    # Return results in dictionary\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at nbroad/ESG-BERT and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([26]) in the checkpoint and torch.Size([71]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([26, 768]) in the checkpoint and torch.Size([71, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(unique_labels),  # 标签数量\n",
    "    id2label=id2label,              # 标签ID到名称的映射\n",
    "    label2id=label2id,              # 标签名称到ID的映射\n",
    "    ignore_mismatched_sizes=True    # 忽略大小不匹配\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee842688498f45739c45ed1f3eb7cbed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5671 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6bbd308472d46de93713c6fe2318b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1418 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "eval_dataset = eval_dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\esg\\Lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=6, #6个epoch为我研究的最佳周期\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"../logs\",\n",
    "    logging_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Trainer to use compute_metrics function\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8938c54384b41878b4f07dbc7915ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4254 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8491, 'grad_norm': 4.35384464263916, 'learning_rate': 1.99529854254819e-05, 'epoch': 0.01}\n",
      "{'loss': 1.3272, 'grad_norm': 2.523653030395508, 'learning_rate': 1.99059708509638e-05, 'epoch': 0.03}\n",
      "{'loss': 1.2387, 'grad_norm': 3.1073110103607178, 'learning_rate': 1.98589562764457e-05, 'epoch': 0.04}\n",
      "{'loss': 1.4156, 'grad_norm': 2.16011905670166, 'learning_rate': 1.98119417019276e-05, 'epoch': 0.06}\n",
      "{'loss': 1.3951, 'grad_norm': 5.637800216674805, 'learning_rate': 1.9764927127409498e-05, 'epoch': 0.07}\n",
      "{'loss': 1.2785, 'grad_norm': 2.000967264175415, 'learning_rate': 1.9717912552891397e-05, 'epoch': 0.08}\n",
      "{'loss': 1.4653, 'grad_norm': 3.228508472442627, 'learning_rate': 1.9670897978373297e-05, 'epoch': 0.1}\n",
      "{'loss': 1.3966, 'grad_norm': 2.3546903133392334, 'learning_rate': 1.9623883403855196e-05, 'epoch': 0.11}\n",
      "{'loss': 1.1566, 'grad_norm': 1.1956819295883179, 'learning_rate': 1.9576868829337095e-05, 'epoch': 0.13}\n",
      "{'loss': 1.3093, 'grad_norm': 4.243281364440918, 'learning_rate': 1.9529854254818995e-05, 'epoch': 0.14}\n",
      "{'loss': 1.0897, 'grad_norm': 1.6303116083145142, 'learning_rate': 1.9482839680300894e-05, 'epoch': 0.16}\n",
      "{'loss': 1.155, 'grad_norm': 1.5226362943649292, 'learning_rate': 1.9435825105782797e-05, 'epoch': 0.17}\n",
      "{'loss': 1.3558, 'grad_norm': 2.0303537845611572, 'learning_rate': 1.9388810531264696e-05, 'epoch': 0.18}\n",
      "{'loss': 1.1357, 'grad_norm': 2.473972797393799, 'learning_rate': 1.9341795956746595e-05, 'epoch': 0.2}\n",
      "{'loss': 1.1954, 'grad_norm': 1.9874016046524048, 'learning_rate': 1.9294781382228495e-05, 'epoch': 0.21}\n",
      "{'loss': 1.3308, 'grad_norm': 3.273777961730957, 'learning_rate': 1.924776680771039e-05, 'epoch': 0.23}\n",
      "{'loss': 1.0343, 'grad_norm': 1.6944160461425781, 'learning_rate': 1.920075223319229e-05, 'epoch': 0.24}\n",
      "{'loss': 1.3569, 'grad_norm': 4.195617198944092, 'learning_rate': 1.915373765867419e-05, 'epoch': 0.25}\n",
      "{'loss': 1.2622, 'grad_norm': 4.251906394958496, 'learning_rate': 1.910672308415609e-05, 'epoch': 0.27}\n",
      "{'loss': 1.2389, 'grad_norm': 2.2350258827209473, 'learning_rate': 1.9059708509637988e-05, 'epoch': 0.28}\n",
      "{'loss': 1.1081, 'grad_norm': 3.080397129058838, 'learning_rate': 1.9012693935119887e-05, 'epoch': 0.3}\n",
      "{'loss': 1.1801, 'grad_norm': 3.1699211597442627, 'learning_rate': 1.8965679360601786e-05, 'epoch': 0.31}\n",
      "{'loss': 0.9957, 'grad_norm': 2.6792285442352295, 'learning_rate': 1.8918664786083686e-05, 'epoch': 0.32}\n",
      "{'loss': 1.1077, 'grad_norm': 1.5361136198043823, 'learning_rate': 1.8871650211565585e-05, 'epoch': 0.34}\n",
      "{'loss': 1.1502, 'grad_norm': 2.5558395385742188, 'learning_rate': 1.8824635637047484e-05, 'epoch': 0.35}\n",
      "{'loss': 1.3998, 'grad_norm': 1.929206132888794, 'learning_rate': 1.8777621062529384e-05, 'epoch': 0.37}\n",
      "{'loss': 1.1256, 'grad_norm': 2.1109747886657715, 'learning_rate': 1.8730606488011286e-05, 'epoch': 0.38}\n",
      "{'loss': 1.1604, 'grad_norm': 2.0269572734832764, 'learning_rate': 1.8683591913493186e-05, 'epoch': 0.39}\n",
      "{'loss': 1.1928, 'grad_norm': 2.5113015174865723, 'learning_rate': 1.8636577338975085e-05, 'epoch': 0.41}\n",
      "{'loss': 1.037, 'grad_norm': 2.4391608238220215, 'learning_rate': 1.8589562764456984e-05, 'epoch': 0.42}\n",
      "{'loss': 1.376, 'grad_norm': 3.995021104812622, 'learning_rate': 1.8542548189938884e-05, 'epoch': 0.44}\n",
      "{'loss': 1.0459, 'grad_norm': 1.1861590147018433, 'learning_rate': 1.8495533615420783e-05, 'epoch': 0.45}\n",
      "{'loss': 1.2853, 'grad_norm': 2.770892858505249, 'learning_rate': 1.8448519040902682e-05, 'epoch': 0.47}\n",
      "{'loss': 1.1584, 'grad_norm': 2.0266270637512207, 'learning_rate': 1.840150446638458e-05, 'epoch': 0.48}\n",
      "{'loss': 1.1349, 'grad_norm': 1.574530005455017, 'learning_rate': 1.835448989186648e-05, 'epoch': 0.49}\n",
      "{'loss': 1.0279, 'grad_norm': 3.057800769805908, 'learning_rate': 1.830747531734838e-05, 'epoch': 0.51}\n",
      "{'loss': 1.2456, 'grad_norm': 4.841728687286377, 'learning_rate': 1.826046074283028e-05, 'epoch': 0.52}\n",
      "{'loss': 1.2426, 'grad_norm': 3.1518609523773193, 'learning_rate': 1.821344616831218e-05, 'epoch': 0.54}\n",
      "{'loss': 1.2266, 'grad_norm': 2.4570300579071045, 'learning_rate': 1.8166431593794078e-05, 'epoch': 0.55}\n",
      "{'loss': 1.2468, 'grad_norm': 5.842841625213623, 'learning_rate': 1.8119417019275977e-05, 'epoch': 0.56}\n",
      "{'loss': 1.1225, 'grad_norm': 2.6530232429504395, 'learning_rate': 1.8072402444757877e-05, 'epoch': 0.58}\n",
      "{'loss': 1.1939, 'grad_norm': 3.762765645980835, 'learning_rate': 1.8025387870239776e-05, 'epoch': 0.59}\n",
      "{'loss': 1.2028, 'grad_norm': 7.296967029571533, 'learning_rate': 1.7978373295721675e-05, 'epoch': 0.61}\n",
      "{'loss': 0.948, 'grad_norm': 3.5282161235809326, 'learning_rate': 1.7931358721203575e-05, 'epoch': 0.62}\n",
      "{'loss': 1.1751, 'grad_norm': 1.7128256559371948, 'learning_rate': 1.7884344146685474e-05, 'epoch': 0.63}\n",
      "{'loss': 1.0632, 'grad_norm': 2.441105365753174, 'learning_rate': 1.7837329572167373e-05, 'epoch': 0.65}\n",
      "{'loss': 1.243, 'grad_norm': 3.6962506771087646, 'learning_rate': 1.7790314997649273e-05, 'epoch': 0.66}\n",
      "{'loss': 1.1169, 'grad_norm': 1.8869284391403198, 'learning_rate': 1.7743300423131172e-05, 'epoch': 0.68}\n",
      "{'loss': 1.1451, 'grad_norm': 2.5960452556610107, 'learning_rate': 1.769628584861307e-05, 'epoch': 0.69}\n",
      "{'loss': 1.1003, 'grad_norm': 1.768246054649353, 'learning_rate': 1.764927127409497e-05, 'epoch': 0.71}\n",
      "{'loss': 1.1362, 'grad_norm': 3.918738603591919, 'learning_rate': 1.760225669957687e-05, 'epoch': 0.72}\n",
      "{'loss': 1.1614, 'grad_norm': 2.593153953552246, 'learning_rate': 1.755524212505877e-05, 'epoch': 0.73}\n",
      "{'loss': 1.1476, 'grad_norm': 3.2073476314544678, 'learning_rate': 1.750822755054067e-05, 'epoch': 0.75}\n",
      "{'loss': 1.1251, 'grad_norm': 5.141215801239014, 'learning_rate': 1.7461212976022568e-05, 'epoch': 0.76}\n",
      "{'loss': 1.1442, 'grad_norm': 3.658149242401123, 'learning_rate': 1.7414198401504467e-05, 'epoch': 0.78}\n",
      "{'loss': 1.0048, 'grad_norm': 2.296844005584717, 'learning_rate': 1.7367183826986366e-05, 'epoch': 0.79}\n",
      "{'loss': 0.9281, 'grad_norm': 2.359853982925415, 'learning_rate': 1.7320169252468266e-05, 'epoch': 0.8}\n",
      "{'loss': 1.1361, 'grad_norm': 3.374912738800049, 'learning_rate': 1.7273154677950165e-05, 'epoch': 0.82}\n",
      "{'loss': 1.1382, 'grad_norm': 3.237525224685669, 'learning_rate': 1.7226140103432064e-05, 'epoch': 0.83}\n",
      "{'loss': 1.0795, 'grad_norm': 2.61696195602417, 'learning_rate': 1.7179125528913964e-05, 'epoch': 0.85}\n",
      "{'loss': 1.1049, 'grad_norm': 2.534640073776245, 'learning_rate': 1.7132110954395863e-05, 'epoch': 0.86}\n",
      "{'loss': 0.9833, 'grad_norm': 2.8035573959350586, 'learning_rate': 1.7085096379877762e-05, 'epoch': 0.87}\n",
      "{'loss': 1.0724, 'grad_norm': 2.5809738636016846, 'learning_rate': 1.703808180535966e-05, 'epoch': 0.89}\n",
      "{'loss': 0.9271, 'grad_norm': 3.0752577781677246, 'learning_rate': 1.699106723084156e-05, 'epoch': 0.9}\n",
      "{'loss': 1.2354, 'grad_norm': 8.542130470275879, 'learning_rate': 1.6944052656323464e-05, 'epoch': 0.92}\n",
      "{'loss': 0.999, 'grad_norm': 5.162093162536621, 'learning_rate': 1.6897038081805363e-05, 'epoch': 0.93}\n",
      "{'loss': 1.1674, 'grad_norm': 3.1831037998199463, 'learning_rate': 1.6850023507287262e-05, 'epoch': 0.94}\n",
      "{'loss': 0.8876, 'grad_norm': 3.0434012413024902, 'learning_rate': 1.680300893276916e-05, 'epoch': 0.96}\n",
      "{'loss': 0.8475, 'grad_norm': 4.737736225128174, 'learning_rate': 1.675599435825106e-05, 'epoch': 0.97}\n",
      "{'loss': 1.0221, 'grad_norm': 2.112215042114258, 'learning_rate': 1.670897978373296e-05, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ad543659db40b1bbf7e1160226b0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\esg\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0325167179107666, 'eval_accuracy': 0.7961720656100949, 'eval_precision': 0.7256847386549433, 'eval_recall': 0.7961720656100949, 'eval_f1': 0.7358020369387871, 'eval_runtime': 475.0553, 'eval_samples_per_second': 2.985, 'eval_steps_per_second': 0.375, 'epoch': 1.0}\n",
      "{'loss': 1.0991, 'grad_norm': 3.1566436290740967, 'learning_rate': 1.666196520921486e-05, 'epoch': 1.0}\n",
      "{'loss': 1.1199, 'grad_norm': 2.434732437133789, 'learning_rate': 1.661495063469676e-05, 'epoch': 1.02}\n",
      "{'loss': 0.995, 'grad_norm': 2.9561729431152344, 'learning_rate': 1.6567936060178658e-05, 'epoch': 1.03}\n",
      "{'loss': 1.263, 'grad_norm': 4.817466735839844, 'learning_rate': 1.6520921485660557e-05, 'epoch': 1.04}\n",
      "{'loss': 0.879, 'grad_norm': 2.2568297386169434, 'learning_rate': 1.6473906911142457e-05, 'epoch': 1.06}\n",
      "{'loss': 1.017, 'grad_norm': 4.495649337768555, 'learning_rate': 1.6426892336624353e-05, 'epoch': 1.07}\n",
      "{'loss': 0.8955, 'grad_norm': 3.409916877746582, 'learning_rate': 1.6379877762106252e-05, 'epoch': 1.09}\n",
      "{'loss': 0.9, 'grad_norm': 4.743948459625244, 'learning_rate': 1.633286318758815e-05, 'epoch': 1.1}\n",
      "{'loss': 0.8655, 'grad_norm': 3.1931769847869873, 'learning_rate': 1.628584861307005e-05, 'epoch': 1.11}\n",
      "{'loss': 0.8893, 'grad_norm': 5.649590015411377, 'learning_rate': 1.6238834038551953e-05, 'epoch': 1.13}\n",
      "{'loss': 0.9134, 'grad_norm': 4.283200263977051, 'learning_rate': 1.6191819464033853e-05, 'epoch': 1.14}\n",
      "{'loss': 0.9475, 'grad_norm': 1.9589636325836182, 'learning_rate': 1.6144804889515752e-05, 'epoch': 1.16}\n",
      "{'loss': 1.0, 'grad_norm': 3.689920425415039, 'learning_rate': 1.609779031499765e-05, 'epoch': 1.17}\n",
      "{'loss': 0.9719, 'grad_norm': 2.9744157791137695, 'learning_rate': 1.605077574047955e-05, 'epoch': 1.18}\n",
      "{'loss': 1.0911, 'grad_norm': 4.295987129211426, 'learning_rate': 1.600376116596145e-05, 'epoch': 1.2}\n",
      "{'loss': 0.8725, 'grad_norm': 5.395716667175293, 'learning_rate': 1.595674659144335e-05, 'epoch': 1.21}\n",
      "{'loss': 0.766, 'grad_norm': 3.8601293563842773, 'learning_rate': 1.590973201692525e-05, 'epoch': 1.23}\n",
      "{'loss': 0.985, 'grad_norm': 4.747375965118408, 'learning_rate': 1.5862717442407148e-05, 'epoch': 1.24}\n",
      "{'loss': 0.8698, 'grad_norm': 3.34137225151062, 'learning_rate': 1.5815702867889047e-05, 'epoch': 1.26}\n",
      "{'loss': 0.8626, 'grad_norm': 3.9366862773895264, 'learning_rate': 1.5768688293370946e-05, 'epoch': 1.27}\n",
      "{'loss': 0.8694, 'grad_norm': 2.6909542083740234, 'learning_rate': 1.5721673718852846e-05, 'epoch': 1.28}\n",
      "{'loss': 1.0808, 'grad_norm': 3.0886387825012207, 'learning_rate': 1.5674659144334745e-05, 'epoch': 1.3}\n",
      "{'loss': 0.9337, 'grad_norm': 2.744016170501709, 'learning_rate': 1.5627644569816644e-05, 'epoch': 1.31}\n",
      "{'loss': 0.8802, 'grad_norm': 3.5015475749969482, 'learning_rate': 1.5580629995298544e-05, 'epoch': 1.33}\n",
      "{'loss': 1.0467, 'grad_norm': 3.519036054611206, 'learning_rate': 1.5533615420780443e-05, 'epoch': 1.34}\n",
      "{'loss': 0.7883, 'grad_norm': 3.0779037475585938, 'learning_rate': 1.5486600846262342e-05, 'epoch': 1.35}\n",
      "{'loss': 0.9326, 'grad_norm': 3.416447162628174, 'learning_rate': 1.543958627174424e-05, 'epoch': 1.37}\n",
      "{'loss': 0.9402, 'grad_norm': 4.825878620147705, 'learning_rate': 1.539257169722614e-05, 'epoch': 1.38}\n",
      "{'loss': 0.9615, 'grad_norm': 2.4895265102386475, 'learning_rate': 1.534555712270804e-05, 'epoch': 1.4}\n",
      "{'loss': 0.926, 'grad_norm': 3.111664295196533, 'learning_rate': 1.529854254818994e-05, 'epoch': 1.41}\n",
      "{'loss': 1.0362, 'grad_norm': 3.711699962615967, 'learning_rate': 1.525152797367184e-05, 'epoch': 1.42}\n",
      "{'loss': 0.9448, 'grad_norm': 2.4676170349121094, 'learning_rate': 1.520451339915374e-05, 'epoch': 1.44}\n",
      "{'loss': 0.8206, 'grad_norm': 2.8612470626831055, 'learning_rate': 1.5157498824635639e-05, 'epoch': 1.45}\n",
      "{'loss': 1.0475, 'grad_norm': 2.6071438789367676, 'learning_rate': 1.5110484250117538e-05, 'epoch': 1.47}\n",
      "{'loss': 0.8197, 'grad_norm': 3.2284300327301025, 'learning_rate': 1.5063469675599438e-05, 'epoch': 1.48}\n",
      "{'loss': 0.903, 'grad_norm': 4.037567615509033, 'learning_rate': 1.5016455101081337e-05, 'epoch': 1.5}\n",
      "{'loss': 0.9852, 'grad_norm': 3.3773114681243896, 'learning_rate': 1.4969440526563235e-05, 'epoch': 1.51}\n",
      "{'loss': 0.9291, 'grad_norm': 4.020560264587402, 'learning_rate': 1.4922425952045134e-05, 'epoch': 1.52}\n",
      "{'loss': 1.0032, 'grad_norm': 3.392071008682251, 'learning_rate': 1.4875411377527033e-05, 'epoch': 1.54}\n",
      "{'loss': 0.8214, 'grad_norm': 2.502769947052002, 'learning_rate': 1.4828396803008933e-05, 'epoch': 1.55}\n",
      "{'loss': 0.7451, 'grad_norm': 3.0222158432006836, 'learning_rate': 1.4781382228490832e-05, 'epoch': 1.57}\n",
      "{'loss': 0.9047, 'grad_norm': 4.12820291519165, 'learning_rate': 1.4734367653972733e-05, 'epoch': 1.58}\n",
      "{'loss': 0.7534, 'grad_norm': 3.1314618587493896, 'learning_rate': 1.4687353079454632e-05, 'epoch': 1.59}\n",
      "{'loss': 0.804, 'grad_norm': 2.9560065269470215, 'learning_rate': 1.4640338504936531e-05, 'epoch': 1.61}\n",
      "{'loss': 0.899, 'grad_norm': 5.141022205352783, 'learning_rate': 1.459332393041843e-05, 'epoch': 1.62}\n",
      "{'loss': 0.8154, 'grad_norm': 4.8465681076049805, 'learning_rate': 1.454630935590033e-05, 'epoch': 1.64}\n",
      "{'loss': 0.845, 'grad_norm': 4.532301425933838, 'learning_rate': 1.449929478138223e-05, 'epoch': 1.65}\n",
      "{'loss': 0.8044, 'grad_norm': 4.546224594116211, 'learning_rate': 1.4452280206864129e-05, 'epoch': 1.66}\n",
      "{'loss': 0.7564, 'grad_norm': 2.1642513275146484, 'learning_rate': 1.4405265632346028e-05, 'epoch': 1.68}\n",
      "{'loss': 0.9393, 'grad_norm': 3.949547290802002, 'learning_rate': 1.4358251057827927e-05, 'epoch': 1.69}\n",
      "{'loss': 0.9478, 'grad_norm': 3.4113001823425293, 'learning_rate': 1.4311236483309827e-05, 'epoch': 1.71}\n",
      "{'loss': 0.8899, 'grad_norm': 2.2347238063812256, 'learning_rate': 1.4264221908791726e-05, 'epoch': 1.72}\n",
      "{'loss': 0.7796, 'grad_norm': 3.258618116378784, 'learning_rate': 1.4217207334273625e-05, 'epoch': 1.73}\n",
      "{'loss': 0.7564, 'grad_norm': 2.928467273712158, 'learning_rate': 1.4170192759755526e-05, 'epoch': 1.75}\n",
      "{'loss': 0.9207, 'grad_norm': 3.4858646392822266, 'learning_rate': 1.4123178185237426e-05, 'epoch': 1.76}\n",
      "{'loss': 0.8447, 'grad_norm': 4.457683563232422, 'learning_rate': 1.4076163610719325e-05, 'epoch': 1.78}\n",
      "{'loss': 0.8297, 'grad_norm': 4.067320823669434, 'learning_rate': 1.4029149036201224e-05, 'epoch': 1.79}\n",
      "{'loss': 0.6843, 'grad_norm': 4.925399303436279, 'learning_rate': 1.3982134461683123e-05, 'epoch': 1.81}\n",
      "{'loss': 0.6824, 'grad_norm': 2.577080249786377, 'learning_rate': 1.3935119887165023e-05, 'epoch': 1.82}\n",
      "{'loss': 0.7911, 'grad_norm': 2.976666212081909, 'learning_rate': 1.3888105312646922e-05, 'epoch': 1.83}\n",
      "{'loss': 0.8401, 'grad_norm': 7.213761329650879, 'learning_rate': 1.3841090738128821e-05, 'epoch': 1.85}\n",
      "{'loss': 0.8575, 'grad_norm': 3.166672468185425, 'learning_rate': 1.379407616361072e-05, 'epoch': 1.86}\n",
      "{'loss': 0.7753, 'grad_norm': 3.011597156524658, 'learning_rate': 1.374706158909262e-05, 'epoch': 1.88}\n",
      "{'loss': 0.7733, 'grad_norm': 2.931440591812134, 'learning_rate': 1.370004701457452e-05, 'epoch': 1.89}\n",
      "{'loss': 0.7934, 'grad_norm': 3.9858388900756836, 'learning_rate': 1.365303244005642e-05, 'epoch': 1.9}\n",
      "{'loss': 0.8838, 'grad_norm': 8.38272762298584, 'learning_rate': 1.360601786553832e-05, 'epoch': 1.92}\n",
      "{'loss': 0.8002, 'grad_norm': 2.501460552215576, 'learning_rate': 1.3559003291020216e-05, 'epoch': 1.93}\n",
      "{'loss': 0.9137, 'grad_norm': 3.9893746376037598, 'learning_rate': 1.3511988716502115e-05, 'epoch': 1.95}\n",
      "{'loss': 0.7402, 'grad_norm': 3.0164897441864014, 'learning_rate': 1.3464974141984016e-05, 'epoch': 1.96}\n",
      "{'loss': 0.8324, 'grad_norm': 5.764802932739258, 'learning_rate': 1.3417959567465915e-05, 'epoch': 1.97}\n",
      "{'loss': 0.7864, 'grad_norm': 4.772730827331543, 'learning_rate': 1.3370944992947815e-05, 'epoch': 1.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e76f959b3d4f7eb6a4dce2955254ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\esg\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8553321361541748, 'eval_accuracy': 0.8108272134446114, 'eval_precision': 0.773410919359503, 'eval_recall': 0.8108272134446114, 'eval_f1': 0.7717591447485549, 'eval_runtime': 33.245, 'eval_samples_per_second': 42.653, 'eval_steps_per_second': 5.354, 'epoch': 2.0}\n",
      "{'loss': 0.7783, 'grad_norm': 3.988316297531128, 'learning_rate': 1.3323930418429714e-05, 'epoch': 2.0}\n",
      "{'loss': 0.8148, 'grad_norm': 4.2208356857299805, 'learning_rate': 1.3276915843911613e-05, 'epoch': 2.02}\n",
      "{'loss': 0.7797, 'grad_norm': 3.9417612552642822, 'learning_rate': 1.3229901269393512e-05, 'epoch': 2.03}\n",
      "{'loss': 0.833, 'grad_norm': 6.075567722320557, 'learning_rate': 1.3182886694875412e-05, 'epoch': 2.05}\n",
      "{'loss': 0.8206, 'grad_norm': 5.0611042976379395, 'learning_rate': 1.3135872120357311e-05, 'epoch': 2.06}\n",
      "{'loss': 0.6727, 'grad_norm': 3.9767425060272217, 'learning_rate': 1.308885754583921e-05, 'epoch': 2.07}\n",
      "{'loss': 0.7853, 'grad_norm': 4.290954113006592, 'learning_rate': 1.304184297132111e-05, 'epoch': 2.09}\n",
      "{'loss': 0.6149, 'grad_norm': 2.7777576446533203, 'learning_rate': 1.2994828396803009e-05, 'epoch': 2.1}\n",
      "{'loss': 0.9006, 'grad_norm': 7.923892498016357, 'learning_rate': 1.294781382228491e-05, 'epoch': 2.12}\n",
      "{'loss': 0.8037, 'grad_norm': 3.3306777477264404, 'learning_rate': 1.290079924776681e-05, 'epoch': 2.13}\n",
      "{'loss': 0.8286, 'grad_norm': 4.278785228729248, 'learning_rate': 1.2853784673248709e-05, 'epoch': 2.14}\n",
      "{'loss': 0.8702, 'grad_norm': 4.854168891906738, 'learning_rate': 1.2806770098730608e-05, 'epoch': 2.16}\n",
      "{'loss': 0.7312, 'grad_norm': 3.047468900680542, 'learning_rate': 1.2759755524212507e-05, 'epoch': 2.17}\n",
      "{'loss': 0.7018, 'grad_norm': 1.2176927328109741, 'learning_rate': 1.2712740949694407e-05, 'epoch': 2.19}\n",
      "{'loss': 0.6726, 'grad_norm': 4.0131096839904785, 'learning_rate': 1.2665726375176306e-05, 'epoch': 2.2}\n",
      "{'loss': 0.6004, 'grad_norm': 3.947702169418335, 'learning_rate': 1.2618711800658205e-05, 'epoch': 2.21}\n",
      "{'loss': 0.8592, 'grad_norm': 5.204117298126221, 'learning_rate': 1.2571697226140104e-05, 'epoch': 2.23}\n",
      "{'loss': 0.7485, 'grad_norm': 3.2878971099853516, 'learning_rate': 1.2524682651622004e-05, 'epoch': 2.24}\n",
      "{'loss': 0.7678, 'grad_norm': 3.6223514080047607, 'learning_rate': 1.2477668077103903e-05, 'epoch': 2.26}\n",
      "{'loss': 0.7723, 'grad_norm': 3.402529001235962, 'learning_rate': 1.2430653502585804e-05, 'epoch': 2.27}\n",
      "{'loss': 0.8237, 'grad_norm': 5.59775447845459, 'learning_rate': 1.2383638928067703e-05, 'epoch': 2.28}\n",
      "{'loss': 0.6933, 'grad_norm': 2.969879627227783, 'learning_rate': 1.2336624353549603e-05, 'epoch': 2.3}\n",
      "{'loss': 0.7819, 'grad_norm': 4.0507493019104, 'learning_rate': 1.2289609779031502e-05, 'epoch': 2.31}\n",
      "{'loss': 0.6706, 'grad_norm': 2.7981832027435303, 'learning_rate': 1.2242595204513401e-05, 'epoch': 2.33}\n",
      "{'loss': 0.7864, 'grad_norm': 4.998910427093506, 'learning_rate': 1.21955806299953e-05, 'epoch': 2.34}\n",
      "{'loss': 0.8049, 'grad_norm': 4.88856840133667, 'learning_rate': 1.21485660554772e-05, 'epoch': 2.36}\n",
      "{'loss': 0.6455, 'grad_norm': 2.6951544284820557, 'learning_rate': 1.2101551480959098e-05, 'epoch': 2.37}\n",
      "{'loss': 0.6737, 'grad_norm': 5.12873649597168, 'learning_rate': 1.2054536906440997e-05, 'epoch': 2.38}\n",
      "{'loss': 0.8552, 'grad_norm': 5.399659156799316, 'learning_rate': 1.2007522331922896e-05, 'epoch': 2.4}\n",
      "{'loss': 0.7382, 'grad_norm': 3.74005389213562, 'learning_rate': 1.1960507757404796e-05, 'epoch': 2.41}\n",
      "{'loss': 0.7125, 'grad_norm': 4.294522285461426, 'learning_rate': 1.1913493182886695e-05, 'epoch': 2.43}\n",
      "{'loss': 0.6469, 'grad_norm': 6.579464912414551, 'learning_rate': 1.1866478608368594e-05, 'epoch': 2.44}\n",
      "{'loss': 0.8012, 'grad_norm': 5.641876697540283, 'learning_rate': 1.1819464033850493e-05, 'epoch': 2.45}\n",
      "{'loss': 0.6991, 'grad_norm': 2.127392053604126, 'learning_rate': 1.1772449459332393e-05, 'epoch': 2.47}\n",
      "{'loss': 0.7107, 'grad_norm': 3.6507351398468018, 'learning_rate': 1.1725434884814294e-05, 'epoch': 2.48}\n",
      "{'loss': 0.6709, 'grad_norm': 6.089094638824463, 'learning_rate': 1.1678420310296193e-05, 'epoch': 2.5}\n",
      "{'loss': 0.7546, 'grad_norm': 9.419652938842773, 'learning_rate': 1.1631405735778092e-05, 'epoch': 2.51}\n",
      "{'loss': 0.6751, 'grad_norm': 3.446424961090088, 'learning_rate': 1.1584391161259992e-05, 'epoch': 2.52}\n",
      "{'loss': 0.7025, 'grad_norm': 4.8763909339904785, 'learning_rate': 1.1537376586741891e-05, 'epoch': 2.54}\n",
      "{'loss': 0.72, 'grad_norm': 4.8354363441467285, 'learning_rate': 1.149036201222379e-05, 'epoch': 2.55}\n",
      "{'loss': 0.7033, 'grad_norm': 5.054183483123779, 'learning_rate': 1.144334743770569e-05, 'epoch': 2.57}\n",
      "{'loss': 0.671, 'grad_norm': 2.9718246459960938, 'learning_rate': 1.1396332863187589e-05, 'epoch': 2.58}\n",
      "{'loss': 0.6448, 'grad_norm': 4.610383987426758, 'learning_rate': 1.1349318288669488e-05, 'epoch': 2.6}\n",
      "{'loss': 0.8504, 'grad_norm': 6.3049187660217285, 'learning_rate': 1.1302303714151388e-05, 'epoch': 2.61}\n",
      "{'loss': 0.7335, 'grad_norm': 2.6405062675476074, 'learning_rate': 1.1255289139633287e-05, 'epoch': 2.62}\n",
      "{'loss': 0.735, 'grad_norm': 4.0165791511535645, 'learning_rate': 1.1208274565115186e-05, 'epoch': 2.64}\n",
      "{'loss': 0.8638, 'grad_norm': 4.317113399505615, 'learning_rate': 1.1161259990597087e-05, 'epoch': 2.65}\n",
      "{'loss': 0.6999, 'grad_norm': 3.184638500213623, 'learning_rate': 1.1114245416078986e-05, 'epoch': 2.67}\n",
      "{'loss': 0.7631, 'grad_norm': 5.8597941398620605, 'learning_rate': 1.1067230841560886e-05, 'epoch': 2.68}\n",
      "{'loss': 0.6618, 'grad_norm': 5.456639289855957, 'learning_rate': 1.1020216267042785e-05, 'epoch': 2.69}\n",
      "{'loss': 0.7116, 'grad_norm': 3.9005932807922363, 'learning_rate': 1.0973201692524684e-05, 'epoch': 2.71}\n",
      "{'loss': 0.714, 'grad_norm': 3.820488929748535, 'learning_rate': 1.0926187118006584e-05, 'epoch': 2.72}\n",
      "{'loss': 0.6002, 'grad_norm': 4.018617153167725, 'learning_rate': 1.0879172543488483e-05, 'epoch': 2.74}\n",
      "{'loss': 0.8158, 'grad_norm': 4.483003616333008, 'learning_rate': 1.0832157968970382e-05, 'epoch': 2.75}\n",
      "{'loss': 0.6849, 'grad_norm': 5.438877582550049, 'learning_rate': 1.0785143394452282e-05, 'epoch': 2.76}\n",
      "{'loss': 0.6287, 'grad_norm': 2.4223744869232178, 'learning_rate': 1.0738128819934181e-05, 'epoch': 2.78}\n",
      "{'loss': 0.7045, 'grad_norm': 3.856787919998169, 'learning_rate': 1.0691114245416079e-05, 'epoch': 2.79}\n",
      "{'loss': 0.7174, 'grad_norm': 8.87738037109375, 'learning_rate': 1.0644099670897978e-05, 'epoch': 2.81}\n",
      "{'loss': 0.6449, 'grad_norm': 5.146842002868652, 'learning_rate': 1.0597085096379877e-05, 'epoch': 2.82}\n",
      "{'loss': 0.7585, 'grad_norm': 3.7926933765411377, 'learning_rate': 1.0550070521861777e-05, 'epoch': 2.83}\n",
      "{'loss': 0.7501, 'grad_norm': 5.6848368644714355, 'learning_rate': 1.0503055947343676e-05, 'epoch': 2.85}\n",
      "{'loss': 0.6461, 'grad_norm': 3.9645652770996094, 'learning_rate': 1.0456041372825577e-05, 'epoch': 2.86}\n",
      "{'loss': 0.6859, 'grad_norm': 2.952922821044922, 'learning_rate': 1.0409026798307476e-05, 'epoch': 2.88}\n",
      "{'loss': 0.6806, 'grad_norm': 5.483880996704102, 'learning_rate': 1.0362012223789375e-05, 'epoch': 2.89}\n",
      "{'loss': 0.9309, 'grad_norm': 12.857635498046875, 'learning_rate': 1.0314997649271275e-05, 'epoch': 2.91}\n",
      "{'loss': 0.6609, 'grad_norm': 4.784148216247559, 'learning_rate': 1.0267983074753174e-05, 'epoch': 2.92}\n",
      "{'loss': 0.6564, 'grad_norm': 4.397903919219971, 'learning_rate': 1.0220968500235073e-05, 'epoch': 2.93}\n",
      "{'loss': 0.6012, 'grad_norm': 2.170586347579956, 'learning_rate': 1.0173953925716973e-05, 'epoch': 2.95}\n",
      "{'loss': 0.5842, 'grad_norm': 5.885293483734131, 'learning_rate': 1.0126939351198872e-05, 'epoch': 2.96}\n",
      "{'loss': 0.6904, 'grad_norm': 6.4092631340026855, 'learning_rate': 1.0079924776680771e-05, 'epoch': 2.98}\n",
      "{'loss': 0.7216, 'grad_norm': 14.795083045959473, 'learning_rate': 1.003291020216267e-05, 'epoch': 2.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c7b62e677d5485ba21ee9984cdabbc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\esg\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7758057117462158, 'eval_accuracy': 0.8198980901059423, 'eval_precision': 0.7875739579715565, 'eval_recall': 0.8198980901059423, 'eval_f1': 0.7900787026898555, 'eval_runtime': 30.4762, 'eval_samples_per_second': 46.528, 'eval_steps_per_second': 5.841, 'epoch': 3.0}\n",
      "{'loss': 0.5846, 'grad_norm': 4.190857410430908, 'learning_rate': 9.98589562764457e-06, 'epoch': 3.0}\n",
      "{'loss': 0.7281, 'grad_norm': 4.774765968322754, 'learning_rate': 9.938881053126471e-06, 'epoch': 3.02}\n",
      "{'loss': 0.707, 'grad_norm': 9.594161987304688, 'learning_rate': 9.89186647860837e-06, 'epoch': 3.03}\n",
      "{'loss': 0.6858, 'grad_norm': 4.385000228881836, 'learning_rate': 9.84485190409027e-06, 'epoch': 3.05}\n",
      "{'loss': 0.6901, 'grad_norm': 3.5962817668914795, 'learning_rate': 9.797837329572169e-06, 'epoch': 3.06}\n",
      "{'loss': 0.5982, 'grad_norm': 2.976015567779541, 'learning_rate': 9.750822755054068e-06, 'epoch': 3.07}\n",
      "{'loss': 0.621, 'grad_norm': 4.290868282318115, 'learning_rate': 9.703808180535967e-06, 'epoch': 3.09}\n",
      "{'loss': 0.7847, 'grad_norm': 6.720495223999023, 'learning_rate': 9.656793606017867e-06, 'epoch': 3.1}\n",
      "{'loss': 0.5951, 'grad_norm': 4.08865213394165, 'learning_rate': 9.609779031499764e-06, 'epoch': 3.12}\n",
      "{'loss': 0.6024, 'grad_norm': 4.306419849395752, 'learning_rate': 9.562764456981665e-06, 'epoch': 3.13}\n",
      "{'loss': 0.7015, 'grad_norm': 3.161893129348755, 'learning_rate': 9.515749882463565e-06, 'epoch': 3.15}\n",
      "{'loss': 0.6321, 'grad_norm': 4.088787078857422, 'learning_rate': 9.468735307945464e-06, 'epoch': 3.16}\n",
      "{'loss': 0.6716, 'grad_norm': 6.334846019744873, 'learning_rate': 9.421720733427363e-06, 'epoch': 3.17}\n",
      "{'loss': 0.5581, 'grad_norm': 2.8252129554748535, 'learning_rate': 9.374706158909263e-06, 'epoch': 3.19}\n",
      "{'loss': 0.7003, 'grad_norm': 3.0986382961273193, 'learning_rate': 9.327691584391162e-06, 'epoch': 3.2}\n",
      "{'loss': 0.5745, 'grad_norm': 3.635983943939209, 'learning_rate': 9.280677009873061e-06, 'epoch': 3.22}\n",
      "{'loss': 0.6393, 'grad_norm': 2.1431705951690674, 'learning_rate': 9.23366243535496e-06, 'epoch': 3.23}\n",
      "{'loss': 0.591, 'grad_norm': 3.601071357727051, 'learning_rate': 9.18664786083686e-06, 'epoch': 3.24}\n",
      "{'loss': 0.7372, 'grad_norm': 6.165053844451904, 'learning_rate': 9.13963328631876e-06, 'epoch': 3.26}\n",
      "{'loss': 0.642, 'grad_norm': 3.960986614227295, 'learning_rate': 9.092618711800659e-06, 'epoch': 3.27}\n",
      "{'loss': 0.6496, 'grad_norm': 4.317891597747803, 'learning_rate': 9.04560413728256e-06, 'epoch': 3.29}\n",
      "{'loss': 0.7754, 'grad_norm': 4.870367050170898, 'learning_rate': 8.998589562764459e-06, 'epoch': 3.3}\n",
      "{'loss': 0.6613, 'grad_norm': 3.1790032386779785, 'learning_rate': 8.951574988246358e-06, 'epoch': 3.31}\n",
      "{'loss': 0.5606, 'grad_norm': 4.675337314605713, 'learning_rate': 8.904560413728256e-06, 'epoch': 3.33}\n",
      "{'loss': 0.7359, 'grad_norm': 5.006886959075928, 'learning_rate': 8.857545839210155e-06, 'epoch': 3.34}\n",
      "{'loss': 0.6677, 'grad_norm': 3.813689708709717, 'learning_rate': 8.810531264692054e-06, 'epoch': 3.36}\n",
      "{'loss': 0.6233, 'grad_norm': 3.3883821964263916, 'learning_rate': 8.763516690173954e-06, 'epoch': 3.37}\n",
      "{'loss': 0.6456, 'grad_norm': 4.890990257263184, 'learning_rate': 8.716502115655853e-06, 'epoch': 3.39}\n",
      "{'loss': 0.6655, 'grad_norm': 4.331958293914795, 'learning_rate': 8.669487541137754e-06, 'epoch': 3.4}\n",
      "{'loss': 0.6393, 'grad_norm': 3.752136707305908, 'learning_rate': 8.622472966619653e-06, 'epoch': 3.41}\n",
      "{'loss': 0.6413, 'grad_norm': 5.151935577392578, 'learning_rate': 8.575458392101553e-06, 'epoch': 3.43}\n",
      "{'loss': 0.5888, 'grad_norm': 4.409257888793945, 'learning_rate': 8.528443817583452e-06, 'epoch': 3.44}\n",
      "{'loss': 0.538, 'grad_norm': 5.326666355133057, 'learning_rate': 8.481429243065351e-06, 'epoch': 3.46}\n",
      "{'loss': 0.5606, 'grad_norm': 4.221342086791992, 'learning_rate': 8.43441466854725e-06, 'epoch': 3.47}\n",
      "{'loss': 0.5661, 'grad_norm': 4.001043319702148, 'learning_rate': 8.38740009402915e-06, 'epoch': 3.48}\n",
      "{'loss': 0.6463, 'grad_norm': 3.3285608291625977, 'learning_rate': 8.34038551951105e-06, 'epoch': 3.5}\n",
      "{'loss': 0.5721, 'grad_norm': 5.876635551452637, 'learning_rate': 8.293370944992948e-06, 'epoch': 3.51}\n",
      "{'loss': 0.5981, 'grad_norm': 5.120334148406982, 'learning_rate': 8.246356370474848e-06, 'epoch': 3.53}\n",
      "{'loss': 0.5254, 'grad_norm': 2.197706460952759, 'learning_rate': 8.199341795956747e-06, 'epoch': 3.54}\n",
      "{'loss': 0.5834, 'grad_norm': 5.808006763458252, 'learning_rate': 8.152327221438646e-06, 'epoch': 3.55}\n",
      "{'loss': 0.5283, 'grad_norm': 4.3596038818359375, 'learning_rate': 8.105312646920546e-06, 'epoch': 3.57}\n",
      "{'loss': 0.702, 'grad_norm': 5.275292873382568, 'learning_rate': 8.058298072402445e-06, 'epoch': 3.58}\n",
      "{'loss': 0.7961, 'grad_norm': 6.294366836547852, 'learning_rate': 8.011283497884344e-06, 'epoch': 3.6}\n",
      "{'loss': 0.5878, 'grad_norm': 3.175861120223999, 'learning_rate': 7.964268923366244e-06, 'epoch': 3.61}\n",
      "{'loss': 0.5438, 'grad_norm': 4.325384616851807, 'learning_rate': 7.917254348848143e-06, 'epoch': 3.62}\n",
      "{'loss': 0.6557, 'grad_norm': 3.5706794261932373, 'learning_rate': 7.870239774330042e-06, 'epoch': 3.64}\n",
      "{'loss': 0.6647, 'grad_norm': 5.0585761070251465, 'learning_rate': 7.823225199811942e-06, 'epoch': 3.65}\n",
      "{'loss': 0.5859, 'grad_norm': 3.8166017532348633, 'learning_rate': 7.776210625293843e-06, 'epoch': 3.67}\n",
      "{'loss': 0.6451, 'grad_norm': 4.347787380218506, 'learning_rate': 7.729196050775742e-06, 'epoch': 3.68}\n",
      "{'loss': 0.6896, 'grad_norm': 3.962181329727173, 'learning_rate': 7.682181476257641e-06, 'epoch': 3.7}\n",
      "{'loss': 0.6661, 'grad_norm': 3.808198928833008, 'learning_rate': 7.63516690173954e-06, 'epoch': 3.71}\n",
      "{'loss': 0.639, 'grad_norm': 10.333407402038574, 'learning_rate': 7.58815232722144e-06, 'epoch': 3.72}\n",
      "{'loss': 0.6004, 'grad_norm': 4.916980266571045, 'learning_rate': 7.541137752703339e-06, 'epoch': 3.74}\n",
      "{'loss': 0.6074, 'grad_norm': 3.328921318054199, 'learning_rate': 7.494123178185238e-06, 'epoch': 3.75}\n",
      "{'loss': 0.6431, 'grad_norm': 6.715485572814941, 'learning_rate': 7.447108603667137e-06, 'epoch': 3.77}\n",
      "{'loss': 0.5691, 'grad_norm': 2.555387496948242, 'learning_rate': 7.400094029149036e-06, 'epoch': 3.78}\n",
      "{'loss': 0.6185, 'grad_norm': 6.656460762023926, 'learning_rate': 7.3530794546309355e-06, 'epoch': 3.79}\n",
      "{'loss': 0.6132, 'grad_norm': 6.575352191925049, 'learning_rate': 7.306064880112836e-06, 'epoch': 3.81}\n",
      "{'loss': 0.6072, 'grad_norm': 4.3541975021362305, 'learning_rate': 7.259050305594735e-06, 'epoch': 3.82}\n",
      "{'loss': 0.6244, 'grad_norm': 6.547567844390869, 'learning_rate': 7.212035731076634e-06, 'epoch': 3.84}\n",
      "{'loss': 0.5593, 'grad_norm': 2.9604132175445557, 'learning_rate': 7.165021156558534e-06, 'epoch': 3.85}\n",
      "{'loss': 0.5974, 'grad_norm': 4.75822114944458, 'learning_rate': 7.118006582040433e-06, 'epoch': 3.86}\n",
      "{'loss': 0.6353, 'grad_norm': 7.87503719329834, 'learning_rate': 7.070992007522332e-06, 'epoch': 3.88}\n",
      "{'loss': 0.5757, 'grad_norm': 5.634819984436035, 'learning_rate': 7.023977433004232e-06, 'epoch': 3.89}\n",
      "{'loss': 0.6638, 'grad_norm': 5.379714012145996, 'learning_rate': 6.976962858486132e-06, 'epoch': 3.91}\n",
      "{'loss': 0.5942, 'grad_norm': 4.002861022949219, 'learning_rate': 6.929948283968031e-06, 'epoch': 3.92}\n",
      "{'loss': 0.5819, 'grad_norm': 3.7333037853240967, 'learning_rate': 6.88293370944993e-06, 'epoch': 3.94}\n",
      "{'loss': 0.4241, 'grad_norm': 2.820465564727783, 'learning_rate': 6.83591913493183e-06, 'epoch': 3.95}\n",
      "{'loss': 0.6167, 'grad_norm': 4.5173444747924805, 'learning_rate': 6.788904560413729e-06, 'epoch': 3.96}\n",
      "{'loss': 0.608, 'grad_norm': 4.189510822296143, 'learning_rate': 6.741889985895627e-06, 'epoch': 3.98}\n",
      "{'loss': 0.5781, 'grad_norm': 5.52932071685791, 'learning_rate': 6.6948754113775276e-06, 'epoch': 3.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478d04ddb1084bd4922de565fc3c2374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\esg\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7251255512237549, 'eval_accuracy': 0.831262143040434, 'eval_precision': 0.7997491804066423, 'eval_recall': 0.831262143040434, 'eval_f1': 0.8053571779240766, 'eval_runtime': 26.973, 'eval_samples_per_second': 52.571, 'eval_steps_per_second': 6.599, 'epoch': 4.0}\n",
      "{'loss': 0.539, 'grad_norm': 5.922379493713379, 'learning_rate': 6.647860836859427e-06, 'epoch': 4.01}\n",
      "{'loss': 0.6144, 'grad_norm': 3.7024693489074707, 'learning_rate': 6.600846262341326e-06, 'epoch': 4.02}\n",
      "{'loss': 0.638, 'grad_norm': 5.994492530822754, 'learning_rate': 6.5538316878232255e-06, 'epoch': 4.03}\n",
      "{'loss': 0.6555, 'grad_norm': 3.4938244819641113, 'learning_rate': 6.506817113305125e-06, 'epoch': 4.05}\n",
      "{'loss': 0.6657, 'grad_norm': 5.328569412231445, 'learning_rate': 6.459802538787024e-06, 'epoch': 4.06}\n",
      "{'loss': 0.6585, 'grad_norm': 5.057304382324219, 'learning_rate': 6.412787964268924e-06, 'epoch': 4.08}\n",
      "{'loss': 0.6704, 'grad_norm': 4.344435691833496, 'learning_rate': 6.365773389750824e-06, 'epoch': 4.09}\n",
      "{'loss': 0.4819, 'grad_norm': 3.687253952026367, 'learning_rate': 6.318758815232723e-06, 'epoch': 4.1}\n",
      "{'loss': 0.6731, 'grad_norm': 4.598195552825928, 'learning_rate': 6.271744240714622e-06, 'epoch': 4.12}\n",
      "{'loss': 0.6186, 'grad_norm': 4.679848670959473, 'learning_rate': 6.2247296661965215e-06, 'epoch': 4.13}\n",
      "{'loss': 0.5687, 'grad_norm': 4.776216506958008, 'learning_rate': 6.177715091678421e-06, 'epoch': 4.15}\n",
      "{'loss': 0.7528, 'grad_norm': 5.689446926116943, 'learning_rate': 6.130700517160321e-06, 'epoch': 4.16}\n",
      "{'loss': 0.5865, 'grad_norm': 4.643597602844238, 'learning_rate': 6.08368594264222e-06, 'epoch': 4.17}\n",
      "{'loss': 0.6925, 'grad_norm': 7.2889251708984375, 'learning_rate': 6.036671368124119e-06, 'epoch': 4.19}\n",
      "{'loss': 0.6472, 'grad_norm': 7.320645809173584, 'learning_rate': 5.989656793606018e-06, 'epoch': 4.2}\n",
      "{'loss': 0.4886, 'grad_norm': 2.79772686958313, 'learning_rate': 5.942642219087917e-06, 'epoch': 4.22}\n",
      "{'loss': 0.5097, 'grad_norm': 6.021749496459961, 'learning_rate': 5.895627644569817e-06, 'epoch': 4.23}\n",
      "{'loss': 0.5654, 'grad_norm': 3.978029251098633, 'learning_rate': 5.848613070051716e-06, 'epoch': 4.25}\n",
      "{'loss': 0.502, 'grad_norm': 3.9346988201141357, 'learning_rate': 5.801598495533616e-06, 'epoch': 4.26}\n",
      "{'loss': 0.5181, 'grad_norm': 7.039454460144043, 'learning_rate': 5.7545839210155155e-06, 'epoch': 4.27}\n",
      "{'loss': 0.7103, 'grad_norm': 3.9778897762298584, 'learning_rate': 5.707569346497415e-06, 'epoch': 4.29}\n",
      "{'loss': 0.5355, 'grad_norm': 5.076401233673096, 'learning_rate': 5.660554771979314e-06, 'epoch': 4.3}\n",
      "{'loss': 0.5726, 'grad_norm': 4.904059410095215, 'learning_rate': 5.613540197461213e-06, 'epoch': 4.32}\n",
      "{'loss': 0.5996, 'grad_norm': 7.1653361320495605, 'learning_rate': 5.566525622943113e-06, 'epoch': 4.33}\n",
      "{'loss': 0.5162, 'grad_norm': 3.4601945877075195, 'learning_rate': 5.519511048425013e-06, 'epoch': 4.34}\n",
      "{'loss': 0.5289, 'grad_norm': 4.289719104766846, 'learning_rate': 5.472496473906912e-06, 'epoch': 4.36}\n",
      "{'loss': 0.5259, 'grad_norm': 3.181241989135742, 'learning_rate': 5.4254818993888115e-06, 'epoch': 4.37}\n",
      "{'loss': 0.6194, 'grad_norm': 4.8737921714782715, 'learning_rate': 5.378467324870711e-06, 'epoch': 4.39}\n",
      "{'loss': 0.7262, 'grad_norm': 6.709534168243408, 'learning_rate': 5.331452750352609e-06, 'epoch': 4.4}\n",
      "{'loss': 0.5516, 'grad_norm': 4.255640029907227, 'learning_rate': 5.2844381758345086e-06, 'epoch': 4.41}\n",
      "{'loss': 0.5368, 'grad_norm': 4.011814594268799, 'learning_rate': 5.237423601316408e-06, 'epoch': 4.43}\n",
      "{'loss': 0.5439, 'grad_norm': 4.250735282897949, 'learning_rate': 5.190409026798307e-06, 'epoch': 4.44}\n",
      "{'loss': 0.6719, 'grad_norm': 3.2356245517730713, 'learning_rate': 5.143394452280207e-06, 'epoch': 4.46}\n",
      "{'loss': 0.5847, 'grad_norm': 3.2786219120025635, 'learning_rate': 5.096379877762107e-06, 'epoch': 4.47}\n",
      "{'loss': 0.4785, 'grad_norm': 3.0465707778930664, 'learning_rate': 5.049365303244006e-06, 'epoch': 4.49}\n",
      "{'loss': 0.4836, 'grad_norm': 6.733992576599121, 'learning_rate': 5.002350728725905e-06, 'epoch': 4.5}\n",
      "{'loss': 0.5883, 'grad_norm': 5.127087593078613, 'learning_rate': 4.955336154207805e-06, 'epoch': 4.51}\n",
      "{'loss': 0.4574, 'grad_norm': 1.8298287391662598, 'learning_rate': 4.908321579689705e-06, 'epoch': 4.53}\n",
      "{'loss': 0.5368, 'grad_norm': 5.355808734893799, 'learning_rate': 4.861307005171604e-06, 'epoch': 4.54}\n",
      "{'loss': 0.5137, 'grad_norm': 5.028988361358643, 'learning_rate': 4.8142924306535025e-06, 'epoch': 4.56}\n",
      "{'loss': 0.5392, 'grad_norm': 7.037346363067627, 'learning_rate': 4.767277856135402e-06, 'epoch': 4.57}\n",
      "{'loss': 0.5631, 'grad_norm': 5.093989372253418, 'learning_rate': 4.720263281617302e-06, 'epoch': 4.58}\n",
      "{'loss': 0.4228, 'grad_norm': 3.690948963165283, 'learning_rate': 4.673248707099201e-06, 'epoch': 4.6}\n",
      "{'loss': 0.5688, 'grad_norm': 4.772711277008057, 'learning_rate': 4.626234132581101e-06, 'epoch': 4.61}\n",
      "{'loss': 0.5064, 'grad_norm': 7.342706203460693, 'learning_rate': 4.579219558063e-06, 'epoch': 4.63}\n",
      "{'loss': 0.4978, 'grad_norm': 3.431859254837036, 'learning_rate': 4.532204983544899e-06, 'epoch': 4.64}\n",
      "{'loss': 0.529, 'grad_norm': 7.578578472137451, 'learning_rate': 4.4851904090267985e-06, 'epoch': 4.65}\n",
      "{'loss': 0.4733, 'grad_norm': 4.786717891693115, 'learning_rate': 4.438175834508698e-06, 'epoch': 4.67}\n",
      "{'loss': 0.4692, 'grad_norm': 6.081547260284424, 'learning_rate': 4.391161259990597e-06, 'epoch': 4.68}\n",
      "{'loss': 0.5198, 'grad_norm': 4.996131896972656, 'learning_rate': 4.3441466854724965e-06, 'epoch': 4.7}\n",
      "{'loss': 0.6144, 'grad_norm': 3.660295009613037, 'learning_rate': 4.297132110954397e-06, 'epoch': 4.71}\n",
      "{'loss': 0.5981, 'grad_norm': 12.168291091918945, 'learning_rate': 4.250117536436296e-06, 'epoch': 4.72}\n",
      "{'loss': 0.552, 'grad_norm': 6.711589336395264, 'learning_rate': 4.203102961918195e-06, 'epoch': 4.74}\n",
      "{'loss': 0.452, 'grad_norm': 5.16434383392334, 'learning_rate': 4.1560883874000945e-06, 'epoch': 4.75}\n",
      "{'loss': 0.5971, 'grad_norm': 3.9112517833709717, 'learning_rate': 4.109073812881994e-06, 'epoch': 4.77}\n",
      "{'loss': 0.4607, 'grad_norm': 2.84399151802063, 'learning_rate': 4.062059238363893e-06, 'epoch': 4.78}\n",
      "{'loss': 0.623, 'grad_norm': 9.12582778930664, 'learning_rate': 4.0150446638457925e-06, 'epoch': 4.8}\n",
      "{'loss': 0.5014, 'grad_norm': 4.91139030456543, 'learning_rate': 3.968030089327692e-06, 'epoch': 4.81}\n",
      "{'loss': 0.6761, 'grad_norm': 7.426455497741699, 'learning_rate': 3.921015514809591e-06, 'epoch': 4.82}\n",
      "{'loss': 0.4828, 'grad_norm': 6.717968940734863, 'learning_rate': 3.87400094029149e-06, 'epoch': 4.84}\n",
      "{'loss': 0.5067, 'grad_norm': 9.071330070495605, 'learning_rate': 3.8269863657733906e-06, 'epoch': 4.85}\n",
      "{'loss': 0.5228, 'grad_norm': 4.844376564025879, 'learning_rate': 3.77997179125529e-06, 'epoch': 4.87}\n",
      "{'loss': 0.6436, 'grad_norm': 3.3758678436279297, 'learning_rate': 3.7329572167371888e-06, 'epoch': 4.88}\n",
      "{'loss': 0.6872, 'grad_norm': 5.492286682128906, 'learning_rate': 3.685942642219088e-06, 'epoch': 4.89}\n",
      "{'loss': 0.4805, 'grad_norm': 3.923248767852783, 'learning_rate': 3.6389280677009874e-06, 'epoch': 4.91}\n",
      "{'loss': 0.5807, 'grad_norm': 6.775900363922119, 'learning_rate': 3.591913493182887e-06, 'epoch': 4.92}\n",
      "{'loss': 0.5902, 'grad_norm': 4.101993083953857, 'learning_rate': 3.5448989186647864e-06, 'epoch': 4.94}\n",
      "{'loss': 0.5347, 'grad_norm': 8.08538818359375, 'learning_rate': 3.4978843441466857e-06, 'epoch': 4.95}\n",
      "{'loss': 0.5895, 'grad_norm': 7.8628435134887695, 'learning_rate': 3.4508697696285855e-06, 'epoch': 4.96}\n",
      "{'loss': 0.6214, 'grad_norm': 5.089210033416748, 'learning_rate': 3.4038551951104848e-06, 'epoch': 4.98}\n",
      "{'loss': 0.5383, 'grad_norm': 5.816756725311279, 'learning_rate': 3.3568406205923837e-06, 'epoch': 4.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a85abd86d946a78599cb531591a050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\esg\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7264559864997864, 'eval_accuracy': 0.8220568528497705, 'eval_precision': 0.8024852369518309, 'eval_recall': 0.8220568528497705, 'eval_f1': 0.8088597793265181, 'eval_runtime': 27.3946, 'eval_samples_per_second': 51.762, 'eval_steps_per_second': 6.498, 'epoch': 5.0}\n",
      "{'loss': 0.5743, 'grad_norm': 4.462850093841553, 'learning_rate': 3.309826046074283e-06, 'epoch': 5.01}\n",
      "{'loss': 0.6058, 'grad_norm': 6.036447048187256, 'learning_rate': 3.2628114715561827e-06, 'epoch': 5.02}\n",
      "{'loss': 0.4825, 'grad_norm': 6.602058410644531, 'learning_rate': 3.215796897038082e-06, 'epoch': 5.04}\n",
      "{'loss': 0.454, 'grad_norm': 3.588064193725586, 'learning_rate': 3.1687823225199813e-06, 'epoch': 5.05}\n",
      "{'loss': 0.4491, 'grad_norm': 6.809605121612549, 'learning_rate': 3.121767748001881e-06, 'epoch': 5.06}\n",
      "{'loss': 0.7287, 'grad_norm': 5.221611022949219, 'learning_rate': 3.0747531734837804e-06, 'epoch': 5.08}\n",
      "{'loss': 0.6082, 'grad_norm': 6.4079389572143555, 'learning_rate': 3.0277385989656793e-06, 'epoch': 5.09}\n",
      "{'loss': 0.6058, 'grad_norm': 3.6031811237335205, 'learning_rate': 2.980724024447579e-06, 'epoch': 5.11}\n",
      "{'loss': 0.5482, 'grad_norm': 3.56827449798584, 'learning_rate': 2.9337094499294783e-06, 'epoch': 5.12}\n",
      "{'loss': 0.5097, 'grad_norm': 3.359046697616577, 'learning_rate': 2.8866948754113776e-06, 'epoch': 5.13}\n",
      "{'loss': 0.6265, 'grad_norm': 4.303782939910889, 'learning_rate': 2.8396803008932774e-06, 'epoch': 5.15}\n",
      "{'loss': 0.6348, 'grad_norm': 7.020308971405029, 'learning_rate': 2.7926657263751767e-06, 'epoch': 5.16}\n",
      "{'loss': 0.4785, 'grad_norm': 5.328732490539551, 'learning_rate': 2.745651151857076e-06, 'epoch': 5.18}\n",
      "{'loss': 0.5324, 'grad_norm': 6.3958234786987305, 'learning_rate': 2.6986365773389757e-06, 'epoch': 5.19}\n",
      "{'loss': 0.5324, 'grad_norm': 8.32992172241211, 'learning_rate': 2.6516220028208746e-06, 'epoch': 5.2}\n",
      "{'loss': 0.5243, 'grad_norm': 8.388248443603516, 'learning_rate': 2.604607428302774e-06, 'epoch': 5.22}\n",
      "{'loss': 0.5127, 'grad_norm': 5.980011463165283, 'learning_rate': 2.557592853784673e-06, 'epoch': 5.23}\n",
      "{'loss': 0.6057, 'grad_norm': 4.560813903808594, 'learning_rate': 2.510578279266573e-06, 'epoch': 5.25}\n",
      "{'loss': 0.5093, 'grad_norm': 3.958791732788086, 'learning_rate': 2.4635637047484723e-06, 'epoch': 5.26}\n",
      "{'loss': 0.4106, 'grad_norm': 6.018855571746826, 'learning_rate': 2.4165491302303716e-06, 'epoch': 5.28}\n",
      "{'loss': 0.5468, 'grad_norm': 8.866914749145508, 'learning_rate': 2.369534555712271e-06, 'epoch': 5.29}\n",
      "{'loss': 0.5777, 'grad_norm': 5.562014579772949, 'learning_rate': 2.32251998119417e-06, 'epoch': 5.3}\n",
      "{'loss': 0.5245, 'grad_norm': 5.403091907501221, 'learning_rate': 2.27550540667607e-06, 'epoch': 5.32}\n",
      "{'loss': 0.4673, 'grad_norm': 7.256662845611572, 'learning_rate': 2.2284908321579692e-06, 'epoch': 5.33}\n",
      "{'loss': 0.5634, 'grad_norm': 12.196921348571777, 'learning_rate': 2.1814762576398685e-06, 'epoch': 5.35}\n",
      "{'loss': 0.4612, 'grad_norm': 3.5404107570648193, 'learning_rate': 2.134461683121768e-06, 'epoch': 5.36}\n",
      "{'loss': 0.4418, 'grad_norm': 5.320886611938477, 'learning_rate': 2.0874471086036676e-06, 'epoch': 5.37}\n",
      "{'loss': 0.524, 'grad_norm': 4.694523334503174, 'learning_rate': 2.0404325340855665e-06, 'epoch': 5.39}\n",
      "{'loss': 0.4861, 'grad_norm': 6.312490463256836, 'learning_rate': 1.993417959567466e-06, 'epoch': 5.4}\n",
      "{'loss': 0.5283, 'grad_norm': 7.494158744812012, 'learning_rate': 1.9464033850493655e-06, 'epoch': 5.42}\n",
      "{'loss': 0.4415, 'grad_norm': 4.02672815322876, 'learning_rate': 1.899388810531265e-06, 'epoch': 5.43}\n",
      "{'loss': 0.4515, 'grad_norm': 4.638840198516846, 'learning_rate': 1.8523742360131641e-06, 'epoch': 5.44}\n",
      "{'loss': 0.4406, 'grad_norm': 3.201998472213745, 'learning_rate': 1.8053596614950637e-06, 'epoch': 5.46}\n",
      "{'loss': 0.4401, 'grad_norm': 4.267853260040283, 'learning_rate': 1.758345086976963e-06, 'epoch': 5.47}\n",
      "{'loss': 0.514, 'grad_norm': 3.7171013355255127, 'learning_rate': 1.7113305124588625e-06, 'epoch': 5.49}\n",
      "{'loss': 0.5923, 'grad_norm': 5.559508800506592, 'learning_rate': 1.6643159379407616e-06, 'epoch': 5.5}\n",
      "{'loss': 0.421, 'grad_norm': 5.152500152587891, 'learning_rate': 1.6173013634226611e-06, 'epoch': 5.51}\n",
      "{'loss': 0.6388, 'grad_norm': 4.217597484588623, 'learning_rate': 1.5702867889045606e-06, 'epoch': 5.53}\n",
      "{'loss': 0.4979, 'grad_norm': 9.39466667175293, 'learning_rate': 1.5232722143864602e-06, 'epoch': 5.54}\n",
      "{'loss': 0.7309, 'grad_norm': 8.21768569946289, 'learning_rate': 1.4762576398683592e-06, 'epoch': 5.56}\n",
      "{'loss': 0.4781, 'grad_norm': 7.518886566162109, 'learning_rate': 1.4292430653502588e-06, 'epoch': 5.57}\n",
      "{'loss': 0.4956, 'grad_norm': 3.6848959922790527, 'learning_rate': 1.382228490832158e-06, 'epoch': 5.59}\n",
      "{'loss': 0.5445, 'grad_norm': 4.774066925048828, 'learning_rate': 1.3352139163140574e-06, 'epoch': 5.6}\n",
      "{'loss': 0.4909, 'grad_norm': 3.533867120742798, 'learning_rate': 1.2881993417959567e-06, 'epoch': 5.61}\n",
      "{'loss': 0.4571, 'grad_norm': 5.117641448974609, 'learning_rate': 1.2411847672778562e-06, 'epoch': 5.63}\n",
      "{'loss': 0.4165, 'grad_norm': 4.070342540740967, 'learning_rate': 1.1941701927597555e-06, 'epoch': 5.64}\n",
      "{'loss': 0.4966, 'grad_norm': 5.935497760772705, 'learning_rate': 1.147155618241655e-06, 'epoch': 5.66}\n",
      "{'loss': 0.5353, 'grad_norm': 4.8609442710876465, 'learning_rate': 1.1001410437235544e-06, 'epoch': 5.67}\n",
      "{'loss': 0.5528, 'grad_norm': 5.940023899078369, 'learning_rate': 1.0531264692054539e-06, 'epoch': 5.68}\n",
      "{'loss': 0.5558, 'grad_norm': 5.300951957702637, 'learning_rate': 1.0061118946873532e-06, 'epoch': 5.7}\n",
      "{'loss': 0.434, 'grad_norm': 3.167339563369751, 'learning_rate': 9.590973201692525e-07, 'epoch': 5.71}\n",
      "{'loss': 0.4443, 'grad_norm': 2.5490167140960693, 'learning_rate': 9.120827456511519e-07, 'epoch': 5.73}\n",
      "{'loss': 0.5396, 'grad_norm': 3.091266393661499, 'learning_rate': 8.650681711330513e-07, 'epoch': 5.74}\n",
      "{'loss': 0.3815, 'grad_norm': 4.985177993774414, 'learning_rate': 8.180535966149506e-07, 'epoch': 5.75}\n",
      "{'loss': 0.5028, 'grad_norm': 7.459898948669434, 'learning_rate': 7.710390220968502e-07, 'epoch': 5.77}\n",
      "{'loss': 0.582, 'grad_norm': 3.6908388137817383, 'learning_rate': 7.240244475787495e-07, 'epoch': 5.78}\n",
      "{'loss': 0.4969, 'grad_norm': 6.37161922454834, 'learning_rate': 6.770098730606489e-07, 'epoch': 5.8}\n",
      "{'loss': 0.4941, 'grad_norm': 3.5341033935546875, 'learning_rate': 6.299952985425482e-07, 'epoch': 5.81}\n",
      "{'loss': 0.5001, 'grad_norm': 4.799396991729736, 'learning_rate': 5.829807240244476e-07, 'epoch': 5.83}\n",
      "{'loss': 0.4622, 'grad_norm': 4.8815388679504395, 'learning_rate': 5.35966149506347e-07, 'epoch': 5.84}\n",
      "{'loss': 0.5146, 'grad_norm': 5.046577453613281, 'learning_rate': 4.889515749882463e-07, 'epoch': 5.85}\n",
      "{'loss': 0.4634, 'grad_norm': 2.3125078678131104, 'learning_rate': 4.4193700047014577e-07, 'epoch': 5.87}\n",
      "{'loss': 0.4808, 'grad_norm': 4.834709167480469, 'learning_rate': 3.949224259520452e-07, 'epoch': 5.88}\n",
      "{'loss': 0.5676, 'grad_norm': 6.278273582458496, 'learning_rate': 3.4790785143394454e-07, 'epoch': 5.9}\n",
      "{'loss': 0.62, 'grad_norm': 3.872220993041992, 'learning_rate': 3.008932769158439e-07, 'epoch': 5.91}\n",
      "{'loss': 0.5646, 'grad_norm': 5.341291904449463, 'learning_rate': 2.538787023977433e-07, 'epoch': 5.92}\n",
      "{'loss': 0.4059, 'grad_norm': 4.8835015296936035, 'learning_rate': 2.0686412787964269e-07, 'epoch': 5.94}\n",
      "{'loss': 0.4707, 'grad_norm': 7.786141395568848, 'learning_rate': 1.5984955336154208e-07, 'epoch': 5.95}\n",
      "{'loss': 0.5517, 'grad_norm': 4.163302421569824, 'learning_rate': 1.1283497884344148e-07, 'epoch': 5.97}\n",
      "{'loss': 0.4296, 'grad_norm': 4.971889972686768, 'learning_rate': 6.582040432534087e-08, 'epoch': 5.98}\n",
      "{'loss': 0.6096, 'grad_norm': 4.882552146911621, 'learning_rate': 1.8805829807240244e-08, 'epoch': 5.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "877c2a49d56e4aa583f4d2d0319cd963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7157347202301025, 'eval_accuracy': 0.8267531801019099, 'eval_precision': 0.8033165829011489, 'eval_recall': 0.8267531801019099, 'eval_f1': 0.8114657748381907, 'eval_runtime': 27.1215, 'eval_samples_per_second': 52.283, 'eval_steps_per_second': 6.563, 'epoch': 6.0}\n",
      "{'train_runtime': 2747.4501, 'train_samples_per_second': 12.385, 'train_steps_per_second': 1.548, 'train_loss': 0.7495251491588777, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\esg\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4254, training_loss=0.7495251491588777, metrics={'train_runtime': 2747.4501, 'train_samples_per_second': 12.385, 'train_steps_per_second': 1.548, 'total_flos': 8896429798115328.0, 'train_loss': 0.7495251491588777, 'epoch': 6.0})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../finetuned_model\\\\tokenizer_config.json',\n",
       " '../finetuned_model\\\\special_tokens_map.json',\n",
       " '../finetuned_model\\\\vocab.txt',\n",
       " '../finetuned_model\\\\added_tokens.json',\n",
       " '../finetuned_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('../finetuned_model')\n",
    "tokenizer.save_pretrained('../finetuned_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载微调后的模型和分词器\n",
    "model_path = \"../finetuned_model\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_path)\n",
    "model = BertForTokenClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\esg\\Lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4adb9cb71f24764b807f9534b3a903a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/704 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4127, 'grad_norm': 4.936605930328369, 'learning_rate': 1.9715909090909092e-05, 'epoch': 0.01}\n",
      "{'loss': 0.5182, 'grad_norm': 5.862741947174072, 'learning_rate': 1.9431818181818182e-05, 'epoch': 0.03}\n",
      "{'loss': 0.5605, 'grad_norm': 6.257969379425049, 'learning_rate': 1.9147727272727276e-05, 'epoch': 0.04}\n",
      "{'loss': 0.4638, 'grad_norm': 3.0369224548339844, 'learning_rate': 1.8863636363636366e-05, 'epoch': 0.06}\n",
      "{'loss': 0.4375, 'grad_norm': 4.453832626342773, 'learning_rate': 1.8579545454545456e-05, 'epoch': 0.07}\n",
      "{'loss': 0.359, 'grad_norm': 2.8654088973999023, 'learning_rate': 1.8295454545454546e-05, 'epoch': 0.09}\n",
      "{'loss': 0.5475, 'grad_norm': 3.86381196975708, 'learning_rate': 1.8011363636363636e-05, 'epoch': 0.1}\n",
      "{'loss': 0.4799, 'grad_norm': 4.379912376403809, 'learning_rate': 1.772727272727273e-05, 'epoch': 0.11}\n",
      "{'loss': 0.4022, 'grad_norm': 7.674426078796387, 'learning_rate': 1.744318181818182e-05, 'epoch': 0.13}\n",
      "{'loss': 0.4899, 'grad_norm': 8.123591423034668, 'learning_rate': 1.715909090909091e-05, 'epoch': 0.14}\n",
      "{'loss': 0.4204, 'grad_norm': 3.439157485961914, 'learning_rate': 1.6875e-05, 'epoch': 0.16}\n",
      "{'loss': 0.46, 'grad_norm': 8.43388843536377, 'learning_rate': 1.6590909090909094e-05, 'epoch': 0.17}\n",
      "{'loss': 0.4499, 'grad_norm': 6.544565677642822, 'learning_rate': 1.6306818181818184e-05, 'epoch': 0.18}\n",
      "{'loss': 0.3869, 'grad_norm': 2.000539541244507, 'learning_rate': 1.6022727272727274e-05, 'epoch': 0.2}\n",
      "{'loss': 0.5526, 'grad_norm': 6.411473274230957, 'learning_rate': 1.5738636363636364e-05, 'epoch': 0.21}\n",
      "{'loss': 0.5312, 'grad_norm': 5.912090301513672, 'learning_rate': 1.5454545454545454e-05, 'epoch': 0.23}\n",
      "{'loss': 0.4772, 'grad_norm': 2.2216784954071045, 'learning_rate': 1.5170454545454546e-05, 'epoch': 0.24}\n",
      "{'loss': 0.5675, 'grad_norm': 3.5555920600891113, 'learning_rate': 1.4886363636363636e-05, 'epoch': 0.26}\n",
      "{'loss': 0.422, 'grad_norm': 3.237189531326294, 'learning_rate': 1.4602272727272728e-05, 'epoch': 0.27}\n",
      "{'loss': 0.4715, 'grad_norm': 6.0997633934021, 'learning_rate': 1.431818181818182e-05, 'epoch': 0.28}\n",
      "{'loss': 0.4073, 'grad_norm': 5.255706310272217, 'learning_rate': 1.4034090909090909e-05, 'epoch': 0.3}\n",
      "{'loss': 0.3374, 'grad_norm': 3.6380443572998047, 'learning_rate': 1.375e-05, 'epoch': 0.31}\n",
      "{'loss': 0.4513, 'grad_norm': 3.7586464881896973, 'learning_rate': 1.3465909090909092e-05, 'epoch': 0.33}\n",
      "{'loss': 0.5782, 'grad_norm': 8.039941787719727, 'learning_rate': 1.3181818181818183e-05, 'epoch': 0.34}\n",
      "{'loss': 0.4849, 'grad_norm': 10.568500518798828, 'learning_rate': 1.2897727272727274e-05, 'epoch': 0.36}\n",
      "{'loss': 0.4041, 'grad_norm': 3.3722846508026123, 'learning_rate': 1.2613636363636366e-05, 'epoch': 0.37}\n",
      "{'loss': 0.537, 'grad_norm': 6.730622291564941, 'learning_rate': 1.2329545454545455e-05, 'epoch': 0.38}\n",
      "{'loss': 0.3809, 'grad_norm': 5.773416519165039, 'learning_rate': 1.2045454545454547e-05, 'epoch': 0.4}\n",
      "{'loss': 0.4681, 'grad_norm': 9.580763816833496, 'learning_rate': 1.1761363636363637e-05, 'epoch': 0.41}\n",
      "{'loss': 0.5404, 'grad_norm': 5.892344951629639, 'learning_rate': 1.1477272727272729e-05, 'epoch': 0.43}\n",
      "{'loss': 0.4053, 'grad_norm': 6.172807693481445, 'learning_rate': 1.119318181818182e-05, 'epoch': 0.44}\n",
      "{'loss': 0.5436, 'grad_norm': 6.1491899490356445, 'learning_rate': 1.0909090909090909e-05, 'epoch': 0.45}\n",
      "{'loss': 0.4517, 'grad_norm': 5.500960350036621, 'learning_rate': 1.0625e-05, 'epoch': 0.47}\n",
      "{'loss': 0.4594, 'grad_norm': 9.37568473815918, 'learning_rate': 1.0340909090909093e-05, 'epoch': 0.48}\n",
      "{'loss': 0.4428, 'grad_norm': 2.938939094543457, 'learning_rate': 1.0056818181818183e-05, 'epoch': 0.5}\n",
      "{'loss': 0.6279, 'grad_norm': 5.031502723693848, 'learning_rate': 9.772727272727273e-06, 'epoch': 0.51}\n",
      "{'loss': 0.3751, 'grad_norm': 4.78665018081665, 'learning_rate': 9.488636363636365e-06, 'epoch': 0.53}\n",
      "{'loss': 0.526, 'grad_norm': 4.854403018951416, 'learning_rate': 9.204545454545455e-06, 'epoch': 0.54}\n",
      "{'loss': 0.3342, 'grad_norm': 5.116448402404785, 'learning_rate': 8.920454545454547e-06, 'epoch': 0.55}\n",
      "{'loss': 0.5681, 'grad_norm': 11.338844299316406, 'learning_rate': 8.636363636363637e-06, 'epoch': 0.57}\n",
      "{'loss': 0.4592, 'grad_norm': 8.25546646118164, 'learning_rate': 8.352272727272727e-06, 'epoch': 0.58}\n",
      "{'loss': 0.4937, 'grad_norm': 5.859410762786865, 'learning_rate': 8.068181818181819e-06, 'epoch': 0.6}\n",
      "{'loss': 0.5796, 'grad_norm': 6.7188191413879395, 'learning_rate': 7.784090909090911e-06, 'epoch': 0.61}\n",
      "{'loss': 0.4276, 'grad_norm': 8.049236297607422, 'learning_rate': 7.500000000000001e-06, 'epoch': 0.62}\n",
      "{'loss': 0.4845, 'grad_norm': 5.14323091506958, 'learning_rate': 7.215909090909091e-06, 'epoch': 0.64}\n",
      "{'loss': 0.418, 'grad_norm': 8.373430252075195, 'learning_rate': 6.931818181818183e-06, 'epoch': 0.65}\n",
      "{'loss': 0.3736, 'grad_norm': 10.851461410522461, 'learning_rate': 6.647727272727273e-06, 'epoch': 0.67}\n",
      "{'loss': 0.5511, 'grad_norm': 5.671714782714844, 'learning_rate': 6.363636363636364e-06, 'epoch': 0.68}\n",
      "{'loss': 0.5351, 'grad_norm': 6.240962505340576, 'learning_rate': 6.079545454545454e-06, 'epoch': 0.7}\n",
      "{'loss': 0.4257, 'grad_norm': 5.29931116104126, 'learning_rate': 5.795454545454546e-06, 'epoch': 0.71}\n",
      "{'loss': 0.6522, 'grad_norm': 11.094645500183105, 'learning_rate': 5.511363636363637e-06, 'epoch': 0.72}\n",
      "{'loss': 0.4566, 'grad_norm': 6.4509148597717285, 'learning_rate': 5.2272727272727274e-06, 'epoch': 0.74}\n",
      "{'loss': 0.443, 'grad_norm': 8.712138175964355, 'learning_rate': 4.9431818181818184e-06, 'epoch': 0.75}\n",
      "{'loss': 0.5474, 'grad_norm': 9.615008354187012, 'learning_rate': 4.6590909090909095e-06, 'epoch': 0.77}\n",
      "{'loss': 0.4387, 'grad_norm': 6.85824728012085, 'learning_rate': 4.3750000000000005e-06, 'epoch': 0.78}\n",
      "{'loss': 0.5762, 'grad_norm': 5.561090469360352, 'learning_rate': 4.0909090909090915e-06, 'epoch': 0.8}\n",
      "{'loss': 0.5884, 'grad_norm': 4.997582912445068, 'learning_rate': 3.806818181818182e-06, 'epoch': 0.81}\n",
      "{'loss': 0.5169, 'grad_norm': 4.648664951324463, 'learning_rate': 3.522727272727273e-06, 'epoch': 0.82}\n",
      "{'loss': 0.5128, 'grad_norm': 7.274831295013428, 'learning_rate': 3.2386363636363637e-06, 'epoch': 0.84}\n",
      "{'loss': 0.3712, 'grad_norm': 3.1548683643341064, 'learning_rate': 2.954545454545455e-06, 'epoch': 0.85}\n",
      "{'loss': 0.5857, 'grad_norm': 4.2050909996032715, 'learning_rate': 2.6704545454545457e-06, 'epoch': 0.87}\n",
      "{'loss': 0.722, 'grad_norm': 7.999214172363281, 'learning_rate': 2.3863636363636367e-06, 'epoch': 0.88}\n",
      "{'loss': 0.6141, 'grad_norm': 5.075268268585205, 'learning_rate': 2.1022727272727277e-06, 'epoch': 0.89}\n",
      "{'loss': 0.5166, 'grad_norm': 9.012750625610352, 'learning_rate': 1.8181818181818183e-06, 'epoch': 0.91}\n",
      "{'loss': 0.5994, 'grad_norm': 12.424858093261719, 'learning_rate': 1.5340909090909093e-06, 'epoch': 0.92}\n",
      "{'loss': 0.6348, 'grad_norm': 5.102046489715576, 'learning_rate': 1.25e-06, 'epoch': 0.94}\n",
      "{'loss': 0.5204, 'grad_norm': 6.337900161743164, 'learning_rate': 9.65909090909091e-07, 'epoch': 0.95}\n",
      "{'loss': 0.5594, 'grad_norm': 4.5322184562683105, 'learning_rate': 6.818181818181818e-07, 'epoch': 0.97}\n",
      "{'loss': 0.5215, 'grad_norm': 8.165282249450684, 'learning_rate': 3.9772727272727276e-07, 'epoch': 0.98}\n",
      "{'loss': 0.6124, 'grad_norm': 14.71757984161377, 'learning_rate': 1.1363636363636364e-07, 'epoch': 0.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f3d02c25e64373bc7bb32bdcc0ebe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5392122268676758, 'eval_accuracy': 0.86078280389976, 'eval_precision': 0.8499407766536674, 'eval_recall': 0.86078280389976, 'eval_f1': 0.8526105924205835, 'eval_runtime': 138.3475, 'eval_samples_per_second': 10.177, 'eval_steps_per_second': 1.272, 'epoch': 1.0}\n",
      "{'train_runtime': 480.4779, 'train_samples_per_second': 11.72, 'train_steps_per_second': 1.465, 'train_loss': 0.49172663959589874, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\esg\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=704, training_loss=0.49172663959589874, metrics={'train_runtime': 480.4779, 'train_samples_per_second': 11.72, 'train_steps_per_second': 1.465, 'total_flos': 1472279909280768.0, 'train_loss': 0.49172663959589874, 'epoch': 1.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"../logs\",\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# 可以进行增量训练\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查函数：检测句子中是否包含至少一个错误标签\n",
    "def contains_incorrect_label(label_sequence):\n",
    "    # 如果标签序列全是 'O' 标签，则返回 False（保留该句子）\n",
    "    if all(label == \"O\" for label in label_sequence):\n",
    "        return False\n",
    "    # 如果存在标签不在合法标签集中，则返回 True（表示该句子含有错误标签）\n",
    "    return any(label not in label_dict for label in label_sequence)\n",
    "\n",
    "# 检查函数：检测标签是否符合预期\n",
    "def is_incorrect_label_sequence(label_sequence):\n",
    "    for i, label in enumerate(label_sequence):\n",
    "        # 1. 检查标签是否在合法标签集中\n",
    "        if label not in label_dict:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# 找出标错的句子\n",
    "incorrect_labels_df = df[df['ner_tags'].apply(contains_incorrect_label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  tokens  \\\n",
      "0      [i, t,  , s, y, m, b, o, l, i, z, e, s,  , t, ...   \n",
      "43     [s, u, c, h,  , m, e, a, s, u, r, e, s,  , h, ...   \n",
      "156    [i, n,  , a, d, d, i, t, i, o, n,  , ,,  , t, ...   \n",
      "440    [w, e,  , a, r, e,  , a, w, a, r, e,  , t, h, ...   \n",
      "443    [o, u, r,  , a, p, p, r, o, a, c, h,  , t, o, ...   \n",
      "...                                                  ...   \n",
      "11321  [v, a, l, u, e, m, a, x,  , p, u, b, l, i, c, ...   \n",
      "11336  [m, a, n, a, g, e, m, e, n, t,  , t, e, a, m, ...   \n",
      "11364  [b, y,  , s, y, s, t, e, m, a, t, i, c, a, l, ...   \n",
      "11385  [t, o, p, i, c,  , :,  , i, n, d, i, r, e, c, ...   \n",
      "11386  [g, e, n, e, r, a, l,  , s, t, a, n, d, a, r, ...   \n",
      "\n",
      "                                                ner_tags  \n",
      "0      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
      "43     [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
      "156    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-S...  \n",
      "440    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
      "443    [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
      "...                                                  ...  \n",
      "11321  [B-O, B-O, B-O, B-O, B-O, B-O, B-O, B-O, O, O,...  \n",
      "11336  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
      "11364  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
      "11385  [B-O, B-O, B-O, B-O, B-O, O, O, O, B-O, B-O, B...  \n",
      "11386  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
      "\n",
      "[493 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(incorrect_labels_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
